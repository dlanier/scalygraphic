{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e7cc50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a027a41",
   "metadata": {},
   "source": [
    "## 0001 Gradient Resolution (development record)\n",
    "\n",
    "****\n",
    "<a id='toc'></a>\n",
    "### Notebook Table of Contents\n",
    "[Imports](#imports) <br>\n",
    "[Original Image:](#original) <br>\n",
    "[Code:](#code) <br>\n",
    "[Second Difference:](#seconddiffs) <br>\n",
    "****\n",
    "****\n",
    "## TorchIO: datasets \n",
    "TorchIO: [datasets](https://torchio.readthedocs.io/datasets.html) sample slices [plot 3d to 2d](https://torchio.readthedocs.io/auto_examples/plot_3d_to_2d.html) <br>\n",
    "Transformation example: [matplotlib animation](https://torchio.readthedocs.io/auto_examples/plot_video.html) <br>\n",
    "Nifty Net [patch based example](https://niftynet.readthedocs.io/en/dev/window_sizes.html) <br>\n",
    "Visible Human [getting the](https://www.nlm.nih.gov/research/visible/getting_data.html) data [downloads](https://www.nlm.nih.gov/databases/download/vhp.html) <br>\n",
    "[]() <br>\n",
    "\n",
    "****\n",
    "****\n",
    "## Scikit-Image: Measure, Metrics and Marching Cubes \n",
    "Measure module [_Docs_](https://scikit-image.org/docs/stable/api/skimage.measure.html), examples [_Region Properties_](https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_regionprops.html), [](), [](), [](), []() <br>\n",
    "Metrics module [_Docs_](https://scikit-image.org/docs/stable/api/skimage.metrics.html), example [_Hausdorff Distance_](https://scikit-image.org/docs/stable/auto_examples/segmentation/plot_hausdorff_distance.html#sphx-glr-auto-examples-segmentation-plot-hausdorff-distance-py) <br>\n",
    "*****\n",
    "[Marching Cubes](https://scikit-image.org/docs/dev/auto_examples/edges/plot_marching_cubes.html), code definition on [github scikit-image](https://github.com/scikit-image/scikit-image/blob/main/skimage/measure/_marching_cubes_lewiner.py), [](), [](), []() <br>\n",
    "[]() <br>\n",
    "\n",
    "****\n",
    "[]() <br>\n",
    "****\n",
    "## Entropy Threshold Gradient Filter\n",
    "~~~text\n",
    "            change in entropy / change in threshold mask\n",
    "            \n",
    "~~~\n",
    "[](), [](), [](), [](), []() <br>\n",
    "Wikipedia [Entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)) <br>\n",
    "~~~python\n",
    "from skimage import data\n",
    "from skimage.measure import shannon_entropy\n",
    "sh_ent = shannon_entropy(data.camera())\n",
    "# 7.231695011055706\n",
    "~~~\n",
    "****\n",
    "****\n",
    "## DB\n",
    "Towards data science: [sqlite-in-python-and-pandas](https://towardsdatascience.com/an-easy-beginners-guide-to-sqlite-in-python-and-pandas-fbf1f38f6800) <br>\n",
    "[7 essential ops](https://towardsdatascience.com/from-sqlite-to-pandas-7-essential-operations-you-need-to-know-c7a5dd71f232) <br>\n",
    "##### Graph-DB: neo4j:\n",
    "Medium: [create-a-graph-database-in-neo4j-using-python]\n",
    "(https://towardsdatascience.com/create-a-graph-database-in-neo4j-using-python-4172d40f89c4) (db_whatever) \n",
    "##### -mo-betta-consider \n",
    " [sqlite3 (or stalactites maybe)](https://towardsdatascience.com/do-you-know-python-has-a-built-in-database-d553989c87bd). <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96fbcee",
   "metadata": {},
   "source": [
    "# Quaternions as data-type, 3D Gradient operations\n",
    "Free Unified Rendering in Python [pypi FURY](https://pypi.org/project/fury/), [](), [](), []() <br>\n",
    "[Brain Extraction Tool](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BET) <br>\n",
    "Robust Brain Extraction [ROBEX](https://www.nitrc.org/projects/robex) <br>\n",
    "****\n",
    "Berkeley Psyc 214 fall 2016 [dipy](https://bic-berkeley.github.io/psych-214-fall-2016/dipy_registration.html) <br>\n",
    "dipy: [tutorials](https://dipy.org/tutorials/), [](), [](), []() <br>\n",
    "[Open Neuro](https://openneuro.org/) <br>\n",
    "[Oxford FSL](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki) <br>\n",
    "****\n",
    "****\n",
    "[TorchIO dakine](https://torchio.readthedocs.io/index.html) <br>\n",
    "\n",
    "~~~text\n",
    "        HAL seek: ADNI 3 dataset\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8d1040",
   "metadata": {},
   "source": [
    "# TorchIO tutorials cut and paste code\n",
    "[TorchIO docs](https://torchio.readthedocs.io/index.html) <br>\n",
    "[Torchvision docs](https://pytorch.org/vision/stable/index.html) with [data-sets](https://github.com/pytorch/vision) on GitHub <br>\n",
    "Medium: [understanding torchvision functionalities](https://medium.com/swlh/understanding-torchvision-functionalities-for-pytorch-391273299dc9) part one of (almost) three [Part 2](https://medium.com/mlearning-ai/understanding-torchvision-functionalities-for-pytorch-part-2-transforms-886b60d5c23a) DNE [PART 3 DNE]() <br>\n",
    "****\n",
    "<a href=\"sitemap.shtml\">404 Not Found</a>\n",
    "****\n",
    "TorchIO GitHub: [2-3D Unet](https://github.com/fepegar/unet) and [Hi Res Net](https://github.com/fepegar/highresnet) <br>\n",
    "TorchIO: [UNet paper](https://arxiv.org/abs/1505.04597), [3D UNet paper](https://arxiv.org/abs/1606.06650) <br>\n",
    "****\n",
    "PyTorch mathematical (Medium) [5 math functions you didn't know you needed to know](https://medium.com/predict/a-beginners-guide-to-5-pytorch-mathematical-functions-you-didn-t-know-you-needed-2a3e6943a191) <br>\n",
    "****\n",
    "##### PyTorch3D\n",
    "PyTorch3D [dot org](https://pytorch3d.org/) <br>\n",
    "\n",
    "****\n",
    "[Table of Contents (page top)](#toc) <br>\n",
    "### Import \n",
    "#### modules, packages, whatever, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b7e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddeb3900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                            else nibabel writes in red\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#                                            demo examination tools\n",
    "import time, os, sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import quaternion\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import nibabel as nib\n",
    "import ipyvolume as ipv\n",
    "\n",
    "#                                            basic transform demo imports\n",
    "from dipy.viz import regtools\n",
    "from dipy.align.imaffine import AffineMap, MutualInformationMetric, AffineRegistration\n",
    "from dipy.align.transforms import TranslationTransform3D, RigidTransform3D, AffineTransform3D\n",
    "\n",
    "#                                            Non-Linear transform demo imports\n",
    "from dipy.align.imwarp import SymmetricDiffeomorphicRegistration\n",
    "from dipy.align.imwarp import DiffeomorphicMap\n",
    "from dipy.align.metrics import CCMetric\n",
    "\n",
    "nb_after_import_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b5a99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ANDI 3 MR - Flobetapir search Oct 2021_002.xlsx',\n",
       " '.DS_Store',\n",
       " 'MR and 18F PET - Jan 27 2022.xlsx',\n",
       " 'ADNI3_PET_AV45.xlsx',\n",
       " 'ANDI 3 MR - Flobetapir search Oct 2021.xlsx',\n",
       " 'ADNI',\n",
       " 'Meta_ADNI3_3T_3D_AV45']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adni_dir = os.path.abspath('../../../../DATA/Kiaran_ADNI')\n",
    "os.listdir(adni_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b2362aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found:\n",
      "1094596 dicom\n",
      "9522 nifti\n",
      " 1104118 total files 9.273396\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "file_types = ['.nii', '.dcm']\n",
    "adni_image_files_dict = {}\n",
    "nifti_files = []\n",
    "dicom_files = []\n",
    "\n",
    "for d, dl, fl in os.walk(adni_dir):\n",
    "    for f in fl:\n",
    "        f_ext = os.path.splitext(f)[1]\n",
    "        if f_ext in file_types:\n",
    "            full_file = os.path.join(d, f)\n",
    "            if f in adni_image_files_dict:\n",
    "                print('Fooey: duplicates', os.path.join(d, f))\n",
    "            adni_image_files_dict[f] = full_file\n",
    "            if f_ext == '.nii':\n",
    "                nifti_files.append(full_file)\n",
    "            elif f_ext == '.dcm':\n",
    "                dicom_files.append(full_file)\n",
    "                \n",
    "tt = time.time() - t_start\n",
    "\n",
    "print('found:\\n%03i dicom\\n%03i nifti\\n %i total files %0.6f'%(len(dicom_files), \n",
    "                                                               len(nifti_files), \n",
    "                                                               len(adni_image_files_dict),\n",
    "                                                               tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7a5a47",
   "metadata": {},
   "source": [
    "****\n",
    "<a id='original'></a>\n",
    "[Table of Contents (page top)](#toc) <br>\n",
    "[Code](#code) <br>\n",
    "[Second Difference:](#seconddiffs) <br>\n",
    "\n",
    "\n",
    "#### Image file select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36655f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x292f388e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skimage import io\n",
    "import numpy as np\n",
    "data=np.random.randn(5,2)\n",
    "io.imshow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c4ffa29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.ndarray'> 0.0000 803.0000\n",
      "   1 <class 'numpy.memmap'> (182, 256, 256) <class 'numpy.ndarray'> 0.0000 3319.0000\n",
      "   2 <class 'numpy.memmap'> (64, 64, 64, 2) <class 'numpy.ndarray'> 0.0000 13600.0000\n",
      "   3 <class 'numpy.memmap'> (162, 162, 1) <class 'numpy.ndarray'> 0.0000 470.0000\n",
      "   4 <class 'numpy.memmap'> (208, 240, 256) <class 'numpy.ndarray'> 0.0000 880.0000\n",
      "   5 <class 'numpy.memmap'> (128, 128, 46) <class 'numpy.ndarray'> 0.0000 68790.0547\n",
      "   6 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.ndarray'> 0.0000 705.0000\n",
      "   7 <class 'numpy.ndarray'> (80, 80, 52) <class 'numpy.ndarray'> -3.1416 3.1405\n",
      "   8 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.ndarray'> 0.0000 501.0000\n",
      "   9 <class 'numpy.memmap'> (162, 162, 1) <class 'numpy.ndarray'> 0.0000 428.0000\n",
      "  10 <class 'numpy.memmap'> (64, 64, 64, 2) <class 'numpy.ndarray'> 0.0000 6112.0000\n",
      "  11 <class 'numpy.memmap'> (128, 128, 32, 20) <class 'numpy.ndarray'> 0.0000 1095.0000\n",
      "  12 <class 'numpy.ndarray'> (96, 96, 40) <class 'numpy.ndarray'> 0.0000 219.7000\n",
      "  13 <class 'numpy.memmap'> (162, 162, 1) <class 'numpy.ndarray'> 0.0000 558.0000\n",
      "  14 <class 'numpy.ndarray'> (80, 80, 52) <class 'numpy.ndarray'> 0.0000 8471419.7461\n",
      "  15 <class 'numpy.ndarray'> (80, 80, 52) <class 'numpy.ndarray'> 0.0000 10052231.2666\n",
      "  16 <class 'numpy.memmap'> (64, 64, 40, 2) <class 'numpy.ndarray'> 0.0000 4095.0000\n",
      "  17 <class 'numpy.memmap'> (128, 128, 40) <class 'numpy.ndarray'> -19.0000 709.0000\n",
      "  18 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.ndarray'> 0.0000 553.0000\n",
      "  19 <class 'numpy.ndarray'> (128, 128, 90, 4) <class 'numpy.ndarray'> 0.0000 146472.7284\n",
      "  20 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.ndarray'> 0.0000 494.0000\n",
      "  21 <class 'numpy.memmap'> (208, 240, 256) <class 'numpy.ndarray'> 0.0000 597.0000\n",
      "  22 <class 'numpy.memmap'> (128, 128, 40) <class 'numpy.ndarray'> -7.0000 648.0000\n",
      "  23 <class 'numpy.memmap'> (162, 162, 1) <class 'numpy.ndarray'> 0.0000 357.0000\n",
      "  24 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.ndarray'> 0.0000 696.0000\n",
      "  25 <class 'numpy.memmap'> (64, 64, 40, 2) <class 'numpy.ndarray'> 0.0000 2207.0000\n",
      "  26 <class 'numpy.ndarray'> (160, 256, 256) <class 'numpy.ndarray'> 0.0000 326838.6327\n",
      "  27 <class 'numpy.memmap'> (128, 128, 32, 20) <class 'numpy.ndarray'> 0.0000 3161.0000\n",
      "  28 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.ndarray'> 0.0000 648.0000\n",
      "  29 <class 'numpy.memmap'> (230, 230, 175) <class 'numpy.ndarray'> 0.0000 478.0000\n",
      "  30 <class 'numpy.ndarray'> (80, 80, 52) <class 'numpy.ndarray'> 0.0000 14711624.1655\n",
      "  31 <class 'numpy.memmap'> (182, 256, 256) <class 'numpy.ndarray'> 0.0000 4072.0000\n",
      "  32 <class 'numpy.ndarray'> (211, 256, 256) <class 'numpy.ndarray'> 0.0000 51804.0595\n",
      "  33 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.ndarray'> 0.0000 412.0000\n",
      "  34 <class 'numpy.ndarray'> (80, 80, 52) <class 'numpy.ndarray'> 0.0000 7757557.1104\n",
      "  35 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.ndarray'> 0.0000 554.0000\n",
      "  36 <class 'numpy.memmap'> (182, 256, 256) <class 'numpy.ndarray'> 0.0000 3821.0000\n",
      "  37 <class 'numpy.memmap'> (128, 128, 40) <class 'numpy.ndarray'> -101.0000 1441.0000\n",
      "  38 <class 'numpy.memmap'> (128, 128, 40) <class 'numpy.ndarray'> -5.0000 474.0000\n",
      "  39 <class 'numpy.memmap'> (162, 162, 1) <class 'numpy.ndarray'> 0.0000 612.0000\n"
     ]
    }
   ],
   "source": [
    "goodies = [0, 4]\n",
    "for i in range(40):\n",
    "    full_file = nifti_files[i]\n",
    "    # im_data = pydicom.dcmread(full_file).pixel_array\n",
    "    nifty_image = nib.load(full_file)\n",
    "    nifty_image_disp = nifty_image.get_fdata()\n",
    "#     print(i, type(nifty_image_disp), nifty_image_disp.shape, \n",
    "#           type(nifty_image_disp[0]), \n",
    "#           nifty_image_disp.min(), nifty_image_disp.max())\n",
    "\n",
    "#     print('%4i'%(i), str(type(nifty_image_disp)), str(nifty_image_disp.shape), \n",
    "#           str(type(nifty_image_disp[0])), \n",
    "#           '%0.4f'%(nifty_image_disp.min()), '%0.4f'%(nifty_image_disp.max()))\n",
    "    s = ' '.join(('%4i'%(i), str(type(nifty_image_disp)), str(nifty_image_disp.shape), \n",
    "          str(type(nifty_image_disp[0])), \n",
    "          '%0.4f'%(nifty_image_disp.min()), '%0.4f'%(nifty_image_disp.max())))\n",
    "    print(s)\n",
    "# pick one here:\n",
    "full_file = nifti_files[0]\n",
    "nifty_image = nib.load(full_file)\n",
    "nifty_image_disp = nifty_image.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d373824f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected file: /Users/daniellanier/DATA/Kiaran_ADNI/ADNI/_Sagittal_3D_FLAIR_20210621104220_3.nii\n",
      "Opened as type <class 'numpy.memmap'> size: (160, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "print('selected file: %s\\nOpened as type %s size:'%(full_file, type(nifty_image_disp)), nifty_image_disp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e7476c",
   "metadata": {},
   "source": [
    "<a id='code'></a>\n",
    "[Table of Contents (page top)](#toc) <br>\n",
    "[Original Image:](#original) <br>\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a36d0316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quat_zeros(arr_size):\n",
    "    return np.ones(arr_size) * np.quaternion(1,0,0,0)\n",
    "\n",
    "def get_quat_ones(arr_size):\n",
    "    return np.ones(arr_size) * np.quaternion(1,1,1,1)\n",
    "\n",
    "Q_ID_dict = {'w': np.quaternion(1,0,0,0), \n",
    "             'i': np.quaternion(0,1,0,0), \n",
    "             'j': np.quaternion(0,0,1,0), \n",
    "             'k': np.quaternion(0,0,0,1)}\n",
    "\n",
    "def voxels_quaternion_slice_doublets_dict(n_x, n_y, n_z):\n",
    "    # width of central difference in voxels:\n",
    "    qdd = 13                              # 13 quaternions - magnitude divisor\n",
    "    half_shift = 1                        # 1/2 central difference accross voxel\n",
    "    n_shift = half_shift * 2              # indexing central difference for any direction\n",
    "\n",
    "    #     n_x, n_y, n_z = im_arr.shape\n",
    "    #     im_grad_arr = get_quat_ones(im_arr.shape)\n",
    "    im_grad_arr = get_quat_ones((n_x, n_y, n_z))\n",
    "\n",
    "    mid_x = slice(half_shift, n_x - half_shift)\n",
    "    mid_y = slice(half_shift, n_y - half_shift)\n",
    "    mid_z = slice(half_shift, n_z - half_shift)\n",
    "    mddl = (mid_x, mid_y, mid_z)\n",
    "\n",
    "    print('(padded) output shape:', im_grad_arr.shape, '\\ngradient (middle) shape:', im_grad_arr[mddl].shape)\n",
    "    \"\"\"\n",
    "                for i in q_ix:\n",
    "                    G += (b_i - a_i) * q_i    \n",
    "\n",
    "    iterate: each quaternion direction with slices: I[b_slice[x], b_slice[y], b_slice[z]] - I[a_slize[x]...]\n",
    "    \"\"\"\n",
    "\n",
    "    #                                       Vector ~ Slice-a, Slice-b\n",
    "    #                                       on-axis: x, x & y\n",
    "    qx = Q_ID_dict['i']\n",
    "    qx_a = (slice(0, n_x - n_shift), mid_y, mid_z)\n",
    "    qx_b = (slice(n_shift, n_x), mid_y, mid_z)\n",
    "\n",
    "    qy = Q_ID_dict['j']\n",
    "    qy_a = (mid_x, slice(0, n_y - n_shift), mid_z)\n",
    "    qy_b = (mid_x, slice(n_shift, n_y), mid_z)\n",
    "\n",
    "    qz = Q_ID_dict['k']\n",
    "    qz_a = (mid_x, mid_y, slice(0, n_z - n_shift))\n",
    "    qz_b = (mid_x, mid_y, slice(n_shift, n_z))\n",
    "\n",
    "\n",
    "    #                                       in-plane: x+y, x-y, y+z, y-z, z+y\n",
    "    qxy = qx + qy\n",
    "    qxy_a = (slice(0, n_x - n_shift), slice(0, n_y - n_shift), mid_z)\n",
    "    qxy_b = (slice(n_shift, n_x), slice(n_shift, n_y), mid_z)\n",
    "\n",
    "    qx_y = qx - qy\n",
    "    qx_y_a = (slice(0, n_x - n_shift), slice(n_shift, n_y), mid_z)\n",
    "    qx_y_b = (slice(n_shift, n_x), slice(0, n_y - n_shift), mid_z)\n",
    "\n",
    "    qyz = qy + qz\n",
    "    qyz_a = (mid_x, slice(0, n_y - n_shift), slice(0, n_z - n_shift))\n",
    "    qyz_b = (mid_x, slice(n_shift, n_y), slice(n_shift, n_z))\n",
    "\n",
    "    qy_z = qy - qz\n",
    "    qy_z_a = (mid_x, slice(0, n_y - n_shift), slice(n_shift, n_z))\n",
    "    qy_z_b = (mid_x, slice(n_shift, n_y), slice(0, n_z - n_shift))\n",
    "\n",
    "    qzx = qz + qx\n",
    "    qzx_a = (slice(0, n_x - n_shift), mid_y, slice(0, n_z - n_shift))\n",
    "    qzx_b = (slice(n_shift, n_x), mid_y, slice(n_shift, n_z))\n",
    "\n",
    "    qz_x = qz - qx\n",
    "    qx_z_a = (slice(n_shift, n_x), mid_y, slice(0, n_z - n_shift))\n",
    "    qx_z_b = (slice(0, n_x - n_shift), mid_y, slice(n_shift, n_z))\n",
    "\n",
    "\n",
    "    # x, y, z Totally positive\n",
    "    qxyz = qx + qy + qz\n",
    "    qxyz_a = (slice(0, n_x - n_shift), slice(0, n_y - n_shift), slice(0, n_z - n_shift))\n",
    "    qxyz_b = (slice(n_shift, n_x), slice(n_shift, n_y), slice(n_shift, n_z))\n",
    "\n",
    "    # -x, y, z\n",
    "    q_xyz = qy + qz - qx\n",
    "    q_xyz_a = (slice(n_shift, n_x), slice(0, n_y - n_shift), slice(0, n_z - n_shift))\n",
    "    q_xyz_b = (slice(0, n_x - n_shift), slice(n_shift, n_y), slice(n_shift, n_z))\n",
    "\n",
    "    # x, -y, z\n",
    "    qx_yz = qx - qy + qz\n",
    "    qx_yz_a = (slice(0, n_x - n_shift), slice(n_shift, n_y), slice(0, n_z - n_shift))\n",
    "    qx_yz_b = (slice(n_shift, n_x), slice(0, n_y - n_shift), slice(n_shift, n_z))\n",
    "\n",
    "    # x, y, -z\n",
    "    qxy_z = qx + qy - qz\n",
    "    qxy_z_a = (slice(0, n_x - n_shift), slice(0, n_y - n_shift), slice(n_shift, n_z))\n",
    "    qxy_z_b = (slice(n_shift, n_x), slice(n_shift, n_y), slice(0, n_z - n_shift))\n",
    "\n",
    "\n",
    "    vox_pd_vex = {'qx': {'q': qx / qdd, 'a': qx_a, 'b': qx_b}, \n",
    "                  'qy': {'q': qy / qdd, 'a': qy_a, 'b': qy_b}, \n",
    "                  'qz': {'q': qz / qdd, 'a': qz_a, 'b': qz_b},  \n",
    "                  'qxy': {'q': qxy / qdd, 'a': qxy_a, 'b': qxy_b}, \n",
    "                  'qx_y': {'q': qx_y / qdd, 'a': qx_y_a, 'b': qx_y_b}, \n",
    "                  'qyz': {'q': qyz / qdd, 'a': qyz_a, 'b': qyz_b}, \n",
    "                  'qy_z': {'q': qy_z / qdd, 'a': qy_z_a, 'b': qy_z_b}, \n",
    "                  'qzx': {'q': qzx / qdd, 'a': qzx_a, 'b': qzx_b},  \n",
    "                  'qz_x': {'q': qz_x / qdd, 'a': qx_z_a, 'b': qx_z_b}, \n",
    "                  'qxyz': {'q': qxyz / qdd, 'a': qxyz_a, 'b': qxyz_b}, \n",
    "                  'q_xyz': {'q': q_xyz / qdd, 'a': q_xyz_a, 'b': q_xyz_b}, \n",
    "                  'qx_yz': {'q': qx_yz / qdd, 'a': qx_yz_a, 'b': qx_yz_b},\n",
    "                  'qxy_z': {'q': qxy_z / qdd, 'a': qxy_z_a, 'b': qxy_z_b} }\n",
    "    \n",
    "    return vox_pd_vex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dd8552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quat_grad_middle_w_slices_list(arr3D):\n",
    "    \"\"\"middle_slice, slices_list = get_quat_grad_middle_w_slices_list(arr3D)\n",
    "    \"\"\"\n",
    "    slices_list = []\n",
    "    n_x, n_y, n_z = arr3D.shape\n",
    "    \n",
    "    # name the numbers\n",
    "    half_shift = 1\n",
    "    full_shift = 2\n",
    "\n",
    "    zro_x = slice(0, n_x - full_shift)\n",
    "    zro_y = slice(0, n_y - full_shift)\n",
    "    zro_z = slice(0, n_z - full_shift)\n",
    "    \n",
    "    mid_x = slice(half_shift, n_x - half_shift)\n",
    "    mid_y = slice(half_shift, n_y - half_shift)\n",
    "    mid_z = slice(half_shift, n_z - half_shift)\n",
    "    \n",
    "    end_x = slice(full_shift, n_x)\n",
    "    end_y = slice(full_shift, n_y)\n",
    "    end_z = slice(full_shift, n_z)\n",
    "    \n",
    "    middle_slice = (mid_x, mid_y, mid_z)\n",
    "    \n",
    "    for x in [zro_x, mid_x, end_x]:\n",
    "        for y in [zro_y, mid_y, end_y]:\n",
    "            for z in [zro_z, mid_z, end_z]:\n",
    "                temporary_slice = (x,y,z)\n",
    "                if middle_slice == temporary_slice:\n",
    "                    pass\n",
    "                else:\n",
    "                    slices_list.append(temporary_slice)\n",
    "    \n",
    "    return middle_slice, slices_list\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a3b2a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(padded) output shape: (160, 256, 256) \n",
      "gradient (middle) shape: (158, 254, 254)\n",
      "1.764546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((160, 256, 256), (160, 256, 256), None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_quaternion_gradient_II(arr3D):\n",
    "    \"\"\"quat_grad = get_quaternion_gradient_II(arr3D)\n",
    "    \"\"\"\n",
    "    # allocate padded 3d array\n",
    "    quat_diffs = get_quat_zeros(arr3D.shape)\n",
    "    middle_slice, slices_list = get_quat_grad_middle_w_slices_list(arr3D)\n",
    "    arr3D_middle = arr3D[middle_slice]\n",
    "    \n",
    "    for shifter_slice in slices_list:\n",
    "        quat_diffs[middle_slice] += arr3D_middle - arr3D[shifter_slice]\n",
    "        \n",
    "    return quat_diffs\n",
    "\n",
    "def get_quaternion_gradient(quat_arr):\n",
    "    \"\"\" grad_arr = get_quaternion_gradient(quat_arr) \"\"\"\n",
    "    # allocate the return array - same shape as input (padded w q zeros)\n",
    "    grad_arr = get_quat_zeros(quat_arr.shape)\n",
    "    \n",
    "    # name the numbers\n",
    "    half_shift = 1\n",
    "    n_x, n_y, n_z = quat_arr.shape\n",
    "    \n",
    "    mid_x = slice(half_shift, n_x - half_shift)\n",
    "    mid_y = slice(half_shift, n_y - half_shift)\n",
    "    mid_z = slice(half_shift, n_z - half_shift)\n",
    "    mddl = (mid_x, mid_y, mid_z)\n",
    "    \n",
    "    # get the quaternion slices dictionary\n",
    "    for q_name, v in voxels_quaternion_slice_doublets_dict(n_x, n_y, n_z).items():\n",
    "        grad_arr[mddl] += (quat_arr[v['b']] - quat_arr[v['a']])\n",
    "    \n",
    "    return grad_arr\n",
    "\n",
    "\n",
    "def gradient3D(im3_arr):\n",
    "    \n",
    "    # allocate the return array - same shape as input (padded w q zeros)\n",
    "    out_arr = get_quat_zeros(im3_arr.shape)\n",
    "    \n",
    "    # name the numbers\n",
    "    half_shift = 1\n",
    "    n_x, n_y, n_z = im3_arr.shape\n",
    "    \n",
    "    mid_x = slice(half_shift, n_x - half_shift)\n",
    "    mid_y = slice(half_shift, n_y - half_shift)\n",
    "    mid_z = slice(half_shift, n_z - half_shift)\n",
    "    mddl = (mid_x, mid_y, mid_z)\n",
    "    \n",
    "    # get the quaternion slices dictionary\n",
    "    for q_name, v in voxels_quaternion_slice_doublets_dict(n_x, n_y, n_z).items():\n",
    "        out_arr[mddl] += (im3_arr[v['b']] - im3_arr[v['a']]) * v['q']\n",
    "    \n",
    "    return out_arr\n",
    "\n",
    "t0 = time.time()\n",
    "gra_im = gradient3D(nifty_image_disp)\n",
    "\n",
    "nifty_image_disp.shape, gra_im.shape, print('%0.6f'%(time.time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b74e970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, (160, 256, 256), 768, 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def im_norm(im_in):\n",
    "    im_in = im_in - im_in.min()\n",
    "    im_in = im_in / im_in.max()\n",
    "    return im_in\n",
    "\n",
    "def flat_index(float_mat):\n",
    "    \"\"\" convert the input matrix to integers from 0 to number of unique values.\n",
    "    \n",
    "    Args:\n",
    "        float_mat: two dimensional matrix.\n",
    "        \n",
    "    Return:\n",
    "        float_mat: re-enumerated so that the matrix values are all sequential ints.\n",
    "        n_colors:  number of unique values in the input / output matrix\n",
    "    \"\"\"\n",
    "    float_mat_shape = float_mat.shape\n",
    "    \n",
    "    float_mat = np.reshape(float_mat, (1, float_mat.size))\n",
    "    ixA = np.argsort(float_mat)[0]\n",
    "    \n",
    "    current_value = float_mat[0, ixA[0]]\n",
    "    \n",
    "    enumeration_value = 0\n",
    "    for ix in ixA:\n",
    "        if float_mat[0,ix] != current_value:\n",
    "            current_value = float_mat[0,ix]\n",
    "            enumeration_value += 1\n",
    "        float_mat[0,ix] = enumeration_value\n",
    "\n",
    "    float_mat = np.array(np.reshape(float_mat, float_mat_shape))\n",
    "\n",
    "    float_mat = np.int_(float_mat)\n",
    "\n",
    "    return float_mat\n",
    "\n",
    "f_mat  = flat_index(nifty_image_disp)\n",
    "type(f_mat), type(f_mat[0]), f_mat.shape, f_mat.max(), f_mat.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c91a7d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# help(os.PathLike)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfc6e95",
   "metadata": {},
   "source": [
    "<a id='original'></a>\n",
    "[Table of Contents (page top)](#toc) <br>\n",
    "[Code](#code) <br>\n",
    "[Second Difference:](#seconddiffs) <br>\n",
    "\n",
    "\n",
    "#### Display: Original \"Input Image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2891e0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7028955638548ef8028e702192de7c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nifty_image_normalized = im_norm(nifty_image_disp)\n",
    "nifty_image_disp.shape, nifty_image_normalized.shape\n",
    "\n",
    "ipv.figure()\n",
    "ipv.volshow(nifty_image_normalized, \n",
    "            level=[0.25, 0.75], \n",
    "            opacity=0.03, \n",
    "            level_width=0.1, \n",
    "            data_min=0, \n",
    "            data_max=1)\n",
    "ipv.view(-30, 40)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfc229a",
   "metadata": {},
   "source": [
    "\n",
    "#### display Original as ranked values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e8617f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d51e35bf5348d0825986fcc7b358ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nifty_image_ranked_disp = flat_index(nifty_image_disp)\n",
    "nifty_image_ranked_disp = im_norm(nifty_image_ranked_disp)\n",
    "\n",
    "ipv.figure()\n",
    "ipv.volshow(nifty_image_ranked_disp, level=[0.25, 0.75], opacity=0.03, level_width=0.1, data_min=0, data_max=1)\n",
    "ipv.view(-30, 40)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274525f9",
   "metadata": {},
   "source": [
    "#### Display Gradient Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6077f68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76d9523a7604409b23323b0a9a10611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gra_im = gradient3D(nifty_image_disp) # as called above\n",
    "# Normalize as image\n",
    "grd_mag_im = np.abs(gra_im)\n",
    "grd_mag_im = im_norm(grd_mag_im)\n",
    "\n",
    "# display as point cloud\n",
    "ipv.figure()\n",
    "ipv.volshow(grd_mag_im, level=[0.25, 0.75], opacity=0.03, level_width=0.1, data_min=0, data_max=1)\n",
    "ipv.view(-30, 40)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f2f5d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >= 0.90           34     10485726\n",
      " >= 0.80          207     10485553\n",
      " >= 0.70          708     10485052\n",
      " >= 0.60         1530     10484230\n",
      " >= 0.50         2513     10483247\n",
      " >= 0.40         4097     10481663\n",
      " >= 0.30         7348     10478412\n",
      " >= 0.20        16108     10469652\n",
      " >= 0.10       169471     10316289\n",
      " >= 0.00     10485760            0\n"
     ]
    }
   ],
   "source": [
    "for t in [0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1, 0.0]:\n",
    "    print(' >= %0.2f %12i %12i'%(t, np.sum(grd_mag_im >= t), np.sum(grd_mag_im < t)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4513164e",
   "metadata": {},
   "source": [
    "#### Bone of Contention: 26 neighborhood 1st difference stats as selector in context of whole image visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86c57957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.216\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "quat_grad = get_quaternion_gradient_II(gra_im)\n",
    "\n",
    "tt = time.time() - t0\n",
    "print('%0.3f'%(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "add85351",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9137934be68c49c0b887726ef57d3083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grdII_mag_im = np.abs(quat_grad)\n",
    "# grdII_mag_im = flat_index(grdII_mag_im)\n",
    "grdII_mag_im = im_norm(grdII_mag_im)\n",
    "# grdII_mag_im = grdII_mag_im - grdII_mag_im.min()\n",
    "# grdII_mag_im = grdII_mag_im / grdII_mag_im.max()\n",
    "\n",
    "# display as point cloud\n",
    "ipv.figure()\n",
    "ipv.volshow(grdII_mag_im, level=[0.25, 0.75], opacity=0.03, level_width=0.1, data_min=0, data_max=1)\n",
    "ipv.view(-30, 40)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d1dc54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f5d030b",
   "metadata": {},
   "source": [
    "Berkely Psyc 214: [making and saving new images](https://bic-berkeley.github.io/psych-214-fall-2016/saving_images.html) with nibabel <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c15f42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(padded) output shape: (160, 256, 256) \n",
      "gradient (middle) shape: (158, 254, 254)\n",
      "1.724\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "grad_arr = get_quaternion_gradient(gra_im)\n",
    "print('%0.3f'%(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bb2e4a",
   "metadata": {},
   "source": [
    "<a id='seconddiffs'></a>\n",
    "[Table of Contents (page top)](#toc) <br>\n",
    "[Original Image:](#original) <br>\n",
    "[Code:](#code) <br>\n",
    "\n",
    "#### Second differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60124138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d04701f425463c8509a95d6e1b56aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalize as image quat_grad\n",
    "# grdII_mag_im = np.abs(grad_arr)\n",
    "grdII_mag_im_old = np.abs(grad_arr)\n",
    "grdII_mag_im_old = flat_index(grdII_mag_im_old)\n",
    "grdII_mag_im_old = im_norm(grdII_mag_im_old)\n",
    "\n",
    "# display as point cloud\n",
    "ipv.figure()\n",
    "ipv.volshow(grdII_mag_im_old, level=[0.25, 0.75], opacity=0.03, level_width=0.1, data_min=0, data_max=1)\n",
    "ipv.view(-30, 40)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b02134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbccc756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c7eeef4",
   "metadata": {},
   "source": [
    "##### pasted at breaktime:\n",
    "### details for nibabel saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3637cedc",
   "metadata": {},
   "source": [
    "~~~python\n",
    "# import os, time\n",
    "# import nibabel as nib\n",
    "\n",
    "#                                        Name & write\n",
    "transformed_img = nib.Nifti1Image(transformed, template_img.affine, template_img.header)\n",
    "template_img = nib.Nifti1Image(template_data, template_affine, template_img.header)\n",
    "\n",
    "nib.save(transformed_img, os.path.join(data_dir, 'XXX_transformed_NB1.nii'))\n",
    "nib.save(template_img, os.path.join(data_dir, 'XXX_template_NB1.nii'))\n",
    "\n",
    "tt = time.time() - nb_after_import_start_time\n",
    "print(f'{tt:0.3f} total run time')\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1696cb72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dadb317",
   "metadata": {},
   "source": [
    "### Thank you, Berkley Psyc 214\n",
    "~~~python\n",
    "import time, os\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "from dipy.viz import regtools\n",
    "from dipy.align.imaffine import AffineMap, MutualInformationMetric, AffineRegistration\n",
    "from dipy.align.transforms import TranslationTransform3D, RigidTransform3D, AffineTransform3D\n",
    "\n",
    "# nb_after_import_start_time = time.time()\n",
    "\n",
    "# #                                            file names full path\n",
    "# data_dir = os.path.abspath('../../../../DATA/ADNI_test')\n",
    "\n",
    "# mri_file = 'ADNI_002_S_1155_MR_Accelerated_Sagittal_MPRAGE__br_raw_20170425131856689_29_S558282_I843510.nii'\n",
    "# mri_file = os.path.join(data_dir, mri_file)\n",
    "\n",
    "# pet_file = 'ADNI_002_S_1155_PT_ADNI_Brain_PET__Raw_br_raw_20170421115500090_163_S556709_I841767.nii'\n",
    "# pet_file = os.path.join(data_dir, pet_file)\n",
    "\n",
    "# moving_img = nib.load(mri_file)\n",
    "# template_img = nib.load(pet_file)\n",
    "\n",
    "# moving_data = moving_img.get_fdata()\n",
    "# moving_affine = moving_img.affine\n",
    "\n",
    "# template_data = template_img.get_fdata()\n",
    "# template_affine = template_img.affine\n",
    "\n",
    "# identity = np.eye(4)\n",
    "# affine_map = AffineMap(identity, template_data.shape, template_affine, moving_data.shape, moving_affine)\n",
    "# resampled = affine_map.transform(moving_data)\n",
    "\n",
    "# # The mismatch metric\n",
    "# nbins = 32\n",
    "# sampling_prop = None\n",
    "# metric = MutualInformationMetric(nbins, sampling_prop)\n",
    "\n",
    "# # The optimization strategy\n",
    "# level_iters = [10, 10, 5]    # level_iters = [100, 100, 50] # 43 seconds vs \n",
    "# sigmas = [3.0, 1.0, 0.0]\n",
    "# factors = [4, 2, 1]\n",
    "\n",
    "# affreg = AffineRegistration(metric=metric, level_iters=level_iters, sigmas=sigmas, factors=factors)\n",
    "\n",
    "# transform = TranslationTransform3D()\n",
    "# params0 = None\n",
    "# translation = affreg.optimize(template_data, moving_data, transform, params0, template_affine, moving_affine)\n",
    "\n",
    "# transformed = translation.transform(moving_data)\n",
    "\n",
    "# transform = RigidTransform3D()\n",
    "# rigid = affreg.optimize(template_data, moving_data, transform, params0, template_affine, \n",
    "#                         moving_affine, starting_affine=translation.affine)\n",
    "\n",
    "# transformed = rigid.transform(moving_data)\n",
    "\n",
    "# transform = AffineTransform3D()\n",
    "\n",
    "# # Bump up the iterations to get an more exact fit\n",
    "# affreg.level_iters = [1000, 1000, 100]    # [2000, 2000, 200] # 43 sec vs dkine above\n",
    "\n",
    "# affine = affreg.optimize(template_data, moving_data, transform, params0, template_affine, \n",
    "#                          moving_affine, starting_affine=rigid.affine)\n",
    "\n",
    "# transformed = affine.transform(moving_data)\n",
    "\n",
    "\n",
    "#                                        Name & write\n",
    "transformed_img = nib.Nifti1Image(transformed, template_img.affine, template_img.header)\n",
    "template_img = nib.Nifti1Image(template_data, template_affine, template_img.header)\n",
    "\n",
    "nib.save(transformed_img, os.path.join(data_dir, 'XXX_transformed_NB1.nii'))\n",
    "nib.save(template_img, os.path.join(data_dir, 'XXX_template_NB1.nii'))\n",
    "\n",
    "tt = time.time() - nb_after_import_start_time\n",
    "print(f'{tt:0.3f} total run time')\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd48df0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env] *",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
