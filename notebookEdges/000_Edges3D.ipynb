{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e7cc50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96fbcee",
   "metadata": {},
   "source": [
    "<a id='toc'></a>\n",
    "### Notebook Table of Contents\n",
    "[Imports](#imports) <br>\n",
    "[Original Image:](#original) <br>\n",
    "[Code:](#code) <br>\n",
    "[Second Difference:](#seconddiffs) <br>\n",
    "****\n",
    "# Quaternions as data-type, 3D Gradient operations\n",
    "Free Unified Rendering in Python [pypi FURY](https://pypi.org/project/fury/), [](), [](), []() <br>\n",
    "[Brain Extraction Tool](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BET) <br>\n",
    "Robust Brain Extraction [ROBEX](https://www.nitrc.org/projects/robex) <br>\n",
    "****\n",
    "Berkeley Psyc 214 fall 2016 [dipy](https://bic-berkeley.github.io/psych-214-fall-2016/dipy_registration.html) <br>\n",
    "dipy: [tutorials](https://dipy.org/tutorials/), [](), [](), []() <br>\n",
    "[Open Neuro](https://openneuro.org/) <br>\n",
    "[Oxford FSL](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki) <br>\n",
    "****\n",
    "****\n",
    "[TorchIO dakine](https://torchio.readthedocs.io/index.html) <br>\n",
    "\n",
    "~~~text\n",
    "        HAL seek: ADNI 3 dataset\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8d1040",
   "metadata": {},
   "source": [
    "****\n",
    "[Table of Contents (page top)](#toc) <br>\n",
    "### Import \n",
    "#### modules, packages, whatever, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddeb3900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                            else nibabel writes in red\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#                                            demo examination tools\n",
    "import time, os, sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import quaternion\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import nibabel as nib\n",
    "import ipyvolume as ipv\n",
    "\n",
    "#                                            basic transform demo imports\n",
    "from dipy.viz import regtools\n",
    "from dipy.align.imaffine import AffineMap, MutualInformationMetric, AffineRegistration\n",
    "from dipy.align.transforms import TranslationTransform3D, RigidTransform3D, AffineTransform3D\n",
    "\n",
    "#                                            Non-Linear transform demo imports\n",
    "from dipy.align.imwarp import SymmetricDiffeomorphicRegistration\n",
    "from dipy.align.imwarp import DiffeomorphicMap\n",
    "from dipy.align.metrics import CCMetric\n",
    "\n",
    "nb_after_import_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b5a99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ANDI 3 MR - Flobetapir search Oct 2021_002.xlsx',\n",
       " '.DS_Store',\n",
       " 'MR and 18F PET - Jan 27 2022.xlsx',\n",
       " 'ADNI3_PET_AV45.xlsx',\n",
       " 'ANDI 3 MR - Flobetapir search Oct 2021.xlsx',\n",
       " 'ADNI',\n",
       " 'Meta_ADNI3_3T_3D_AV45']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adni_dir = os.path.abspath('../../../../DATA/Kiaran_ADNI')\n",
    "os.listdir(adni_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b2362aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found:\n",
      "1094596 dicom\n",
      "9522 nifti\n",
      " 1104118 total files 9.169111\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "file_types = ['.nii', '.dcm']\n",
    "adni_image_files_dict = {}\n",
    "nifti_files = []\n",
    "dicom_files = []\n",
    "\n",
    "for d, dl, fl in os.walk(adni_dir):\n",
    "    for f in fl:\n",
    "        f_ext = os.path.splitext(f)[1]\n",
    "        if f_ext in file_types:\n",
    "            full_file = os.path.join(d, f)\n",
    "            if f in adni_image_files_dict:\n",
    "                print('Fooey: duplicates', os.path.join(d, f))\n",
    "            adni_image_files_dict[f] = full_file\n",
    "            if f_ext == '.nii':\n",
    "                nifti_files.append(full_file)\n",
    "            elif f_ext == '.dcm':\n",
    "                dicom_files.append(full_file)\n",
    "                \n",
    "tt = time.time() - t_start\n",
    "\n",
    "print('found:\\n%03i dicom\\n%03i nifti\\n %i total files %0.6f'%(len(dicom_files), \n",
    "                                                               len(nifti_files), \n",
    "                                                               len(adni_image_files_dict),\n",
    "                                                               tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7a5a47",
   "metadata": {},
   "source": [
    "****\n",
    "<a id='original'></a>\n",
    "[Table of Contents (page top)](#toc) <br>\n",
    "[Code](#code) <br>\n",
    "[Second Difference:](#seconddiffs) <br>\n",
    "\n",
    "\n",
    "#### Image file select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c4ffa29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.int16'> 0\n",
      "1 <class 'numpy.memmap'> (182, 256, 256) <class 'numpy.int16'> 0\n",
      "2 <class 'numpy.memmap'> (64, 64, 64, 2) <class 'numpy.memmap'> [8 7]\n",
      "3 <class 'numpy.memmap'> (162, 162, 1) <class 'numpy.int16'> 0\n",
      "4 <class 'numpy.memmap'> (208, 240, 256) <class 'numpy.int16'> 0\n",
      "5 <class 'numpy.memmap'> (128, 128, 46) <class 'numpy.float32'> 0.0\n",
      "6 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.int16'> 0\n",
      "7 <class 'numpy.ndarray'> (80, 80, 52) <class 'numpy.float64'> -3.141592502593994\n",
      "8 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.int16'> 0\n",
      "9 <class 'numpy.memmap'> (162, 162, 1) <class 'numpy.int16'> 0\n",
      "10 <class 'numpy.memmap'> (64, 64, 64, 2) <class 'numpy.memmap'> [4 6]\n",
      "11 <class 'numpy.memmap'> (128, 128, 32, 20) <class 'numpy.memmap'> [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "12 <class 'numpy.ndarray'> (96, 96, 40) <class 'numpy.float64'> 0.0\n",
      "13 <class 'numpy.memmap'> (162, 162, 1) <class 'numpy.int16'> 0\n",
      "14 <class 'numpy.ndarray'> (80, 80, 52) <class 'numpy.float64'> 0.0\n",
      "15 <class 'numpy.ndarray'> (80, 80, 52) <class 'numpy.float64'> 0.0\n",
      "16 <class 'numpy.memmap'> (64, 64, 40, 2) <class 'numpy.memmap'> [0 0]\n",
      "17 <class 'numpy.memmap'> (128, 128, 40) <class 'numpy.int16'> 0\n",
      "18 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.int16'> 0\n",
      "19 <class 'numpy.ndarray'> (128, 128, 90, 4) <class 'numpy.ndarray'> [0. 0. 0. 0.]\n",
      "20 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.int16'> 0\n",
      "21 <class 'numpy.memmap'> (208, 240, 256) <class 'numpy.int16'> 0\n",
      "22 <class 'numpy.memmap'> (128, 128, 40) <class 'numpy.int16'> 0\n",
      "23 <class 'numpy.memmap'> (162, 162, 1) <class 'numpy.int16'> 0\n",
      "24 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.int16'> 0\n",
      "25 <class 'numpy.memmap'> (64, 64, 40, 2) <class 'numpy.memmap'> [0 0]\n",
      "26 <class 'numpy.ndarray'> (160, 256, 256) <class 'numpy.float64'> 0.0\n",
      "27 <class 'numpy.memmap'> (128, 128, 32, 20) <class 'numpy.memmap'> [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "28 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.int16'> 0\n",
      "29 <class 'numpy.memmap'> (230, 230, 175) <class 'numpy.int16'> 0\n",
      "30 <class 'numpy.ndarray'> (80, 80, 52) <class 'numpy.float64'> 0.0\n",
      "31 <class 'numpy.memmap'> (182, 256, 256) <class 'numpy.int16'> 0\n",
      "32 <class 'numpy.ndarray'> (211, 256, 256) <class 'numpy.float64'> 0.0\n",
      "33 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.int16'> 0\n",
      "34 <class 'numpy.ndarray'> (80, 80, 52) <class 'numpy.float64'> 0.0\n",
      "35 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.int16'> 0\n",
      "36 <class 'numpy.memmap'> (182, 256, 256) <class 'numpy.int16'> 0\n",
      "37 <class 'numpy.memmap'> (128, 128, 40) <class 'numpy.int16'> 0\n",
      "38 <class 'numpy.memmap'> (128, 128, 40) <class 'numpy.int16'> 0\n",
      "39 <class 'numpy.memmap'> (162, 162, 1) <class 'numpy.int16'> 0\n"
     ]
    }
   ],
   "source": [
    "goodies = [0, 4]\n",
    "for i in range(40):\n",
    "    full_file = nifti_files[i]\n",
    "    # im_data = pydicom.dcmread(full_file).pixel_array\n",
    "    nifty_image = nib.load(full_file)\n",
    "    nifty_image_disp = nifty_image.get_data()\n",
    "    print(i, type(nifty_image_disp), nifty_image_disp.shape, \n",
    "          type(nifty_image_disp[0,0,0]), nifty_image_disp[0,0,0])\n",
    "    \n",
    "# pick one here:\n",
    "full_file = nifti_files[0]\n",
    "nifty_image = nib.load(full_file)\n",
    "nifty_image_disp = nifty_image.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d373824f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected file: /Users/daniellanier/DATA/Kiaran_ADNI/ADNI/_Sagittal_3D_FLAIR_20210621104220_3.nii\n",
      "Opened as type <class 'numpy.memmap'> size: (160, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "print('selected file: %s\\nOpened as type %s size:'%(full_file, type(nifty_image_disp)), nifty_image_disp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e7476c",
   "metadata": {},
   "source": [
    "<a id='code'></a>\n",
    "[Table of Contents (page top)](#toc) <br>\n",
    "[Original Image:](#original) <br>\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a36d0316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quat_zeros(arr_size):\n",
    "    return np.ones(arr_size) * np.quaternion(1,0,0,0)\n",
    "\n",
    "def get_quat_ones(arr_size):\n",
    "    return np.ones(arr_size) * np.quaternion(1,1,1,1)\n",
    "\n",
    "Q_ID_dict = {'w': np.quaternion(1,0,0,0), \n",
    "             'i': np.quaternion(0,1,0,0), \n",
    "             'j': np.quaternion(0,0,1,0), \n",
    "             'k': np.quaternion(0,0,0,1)}\n",
    "\n",
    "def voxels_quaternion_slice_doublets_dict(n_x, n_y, n_z):\n",
    "    # width of central difference in voxels:\n",
    "    qdd = 13                              # 13 quaternions - magnitude divisor\n",
    "    half_shift = 1                        # 1/2 central difference accross voxel\n",
    "    n_shift = half_shift * 2              # indexing central difference for any direction\n",
    "\n",
    "    #     n_x, n_y, n_z = im_arr.shape\n",
    "    #     im_grad_arr = get_quat_ones(im_arr.shape)\n",
    "    im_grad_arr = get_quat_ones((n_x, n_y, n_z))\n",
    "\n",
    "    mid_x = slice(half_shift, n_x - half_shift)\n",
    "    mid_y = slice(half_shift, n_y - half_shift)\n",
    "    mid_z = slice(half_shift, n_z - half_shift)\n",
    "    mddl = (mid_x, mid_y, mid_z)\n",
    "\n",
    "    print('(padded) output shape:', im_grad_arr.shape, '\\ngradient (middle) shape:', im_grad_arr[mddl].shape)\n",
    "    \"\"\"\n",
    "                for i in q_ix:\n",
    "                    G += (b_i - a_i) * q_i    \n",
    "\n",
    "    iterate: each quaternion direction with slices: I[b_slice[x], b_slice[y], b_slice[z]] - I[a_slize[x]...]\n",
    "    \"\"\"\n",
    "\n",
    "    #                                       Vector ~ Slice-a, Slice-b\n",
    "    #                                       on-axis: x, x & y\n",
    "    qx = Q_ID_dict['i']\n",
    "    qx_a = (slice(0, n_x - n_shift), mid_y, mid_z)\n",
    "    qx_b = (slice(n_shift, n_x), mid_y, mid_z)\n",
    "\n",
    "    qy = Q_ID_dict['j']\n",
    "    qy_a = (mid_x, slice(0, n_y - n_shift), mid_z)\n",
    "    qy_b = (mid_x, slice(n_shift, n_y), mid_z)\n",
    "\n",
    "    qz = Q_ID_dict['k']\n",
    "    qz_a = (mid_x, mid_y, slice(0, n_z - n_shift))\n",
    "    qz_b = (mid_x, mid_y, slice(n_shift, n_z))\n",
    "\n",
    "\n",
    "    #                                       in-plane: x+y, x-y, y+z, y-z, z+y\n",
    "    qxy = qx + qy\n",
    "    qxy_a = (slice(0, n_x - n_shift), slice(0, n_y - n_shift), mid_z)\n",
    "    qxy_b = (slice(n_shift, n_x), slice(n_shift, n_y), mid_z)\n",
    "\n",
    "    qx_y = qx - qy\n",
    "    qx_y_a = (slice(0, n_x - n_shift), slice(n_shift, n_y), mid_z)\n",
    "    qx_y_b = (slice(n_shift, n_x), slice(0, n_y - n_shift), mid_z)\n",
    "\n",
    "    qyz = qy + qz\n",
    "    qyz_a = (mid_x, slice(0, n_y - n_shift), slice(0, n_z - n_shift))\n",
    "    qyz_b = (mid_x, slice(n_shift, n_y), slice(n_shift, n_z))\n",
    "\n",
    "    qy_z = qy - qz\n",
    "    qy_z_a = (mid_x, slice(0, n_y - n_shift), slice(n_shift, n_z))\n",
    "    qy_z_b = (mid_x, slice(n_shift, n_y), slice(0, n_z - n_shift))\n",
    "\n",
    "    qzx = qz + qx\n",
    "    qzx_a = (slice(0, n_x - n_shift), mid_y, slice(0, n_z - n_shift))\n",
    "    qzx_b = (slice(n_shift, n_x), mid_y, slice(n_shift, n_z))\n",
    "\n",
    "    qz_x = qz - qx\n",
    "    qx_z_a = (slice(n_shift, n_x), mid_y, slice(0, n_z - n_shift))\n",
    "    qx_z_b = (slice(0, n_x - n_shift), mid_y, slice(n_shift, n_z))\n",
    "\n",
    "\n",
    "    # x, y, z Totally positive\n",
    "    qxyz = qx + qy + qz\n",
    "    qxyz_a = (slice(0, n_x - n_shift), slice(0, n_y - n_shift), slice(0, n_z - n_shift))\n",
    "    qxyz_b = (slice(n_shift, n_x), slice(n_shift, n_y), slice(n_shift, n_z))\n",
    "\n",
    "    # -x, y, z\n",
    "    q_xyz = qy + qz - qx\n",
    "    q_xyz_a = (slice(n_shift, n_x), slice(0, n_y - n_shift), slice(0, n_z - n_shift))\n",
    "    q_xyz_b = (slice(0, n_x - n_shift), slice(n_shift, n_y), slice(n_shift, n_z))\n",
    "\n",
    "    # x, -y, z\n",
    "    qx_yz = qx - qy + qz\n",
    "    qx_yz_a = (slice(0, n_x - n_shift), slice(n_shift, n_y), slice(0, n_z - n_shift))\n",
    "    qx_yz_b = (slice(n_shift, n_x), slice(0, n_y - n_shift), slice(n_shift, n_z))\n",
    "\n",
    "    # x, y, -z\n",
    "    qxy_z = qx + qy - qz\n",
    "    qxy_z_a = (slice(0, n_x - n_shift), slice(0, n_y - n_shift), slice(n_shift, n_z))\n",
    "    qxy_z_b = (slice(n_shift, n_x), slice(n_shift, n_y), slice(0, n_z - n_shift))\n",
    "\n",
    "\n",
    "    vox_pd_vex = {'qx': {'q': qx / qdd, 'a': qx_a, 'b': qx_b}, \n",
    "                  'qy': {'q': qy / qdd, 'a': qy_a, 'b': qy_b}, \n",
    "                  'qz': {'q': qz / qdd, 'a': qz_a, 'b': qz_b},  \n",
    "                  'qxy': {'q': qxy / qdd, 'a': qxy_a, 'b': qxy_b}, \n",
    "                  'qx_y': {'q': qx_y / qdd, 'a': qx_y_a, 'b': qx_y_b}, \n",
    "                  'qyz': {'q': qyz / qdd, 'a': qyz_a, 'b': qyz_b}, \n",
    "                  'qy_z': {'q': qy_z / qdd, 'a': qy_z_a, 'b': qy_z_b}, \n",
    "                  'qzx': {'q': qzx / qdd, 'a': qzx_a, 'b': qzx_b},  \n",
    "                  'qz_x': {'q': qz_x / qdd, 'a': qx_z_a, 'b': qx_z_b}, \n",
    "                  'qxyz': {'q': qxyz / qdd, 'a': qxyz_a, 'b': qxyz_b}, \n",
    "                  'q_xyz': {'q': q_xyz / qdd, 'a': q_xyz_a, 'b': q_xyz_b}, \n",
    "                  'qx_yz': {'q': qx_yz / qdd, 'a': qx_yz_a, 'b': qx_yz_b},\n",
    "                  'qxy_z': {'q': qxy_z / qdd, 'a': qxy_z_a, 'b': qxy_z_b} }\n",
    "    \n",
    "    return vox_pd_vex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dd8552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quat_grad_middle_w_slices_list(arr3D):\n",
    "    \"\"\"middle_slice, slices_list = get_quat_grad_middle_w_slices_list(arr3D)\n",
    "    \"\"\"\n",
    "    slices_list = []\n",
    "    n_x, n_y, n_z = arr3D.shape\n",
    "    \n",
    "    # name the numbers\n",
    "    half_shift = 1\n",
    "    full_shift = 2\n",
    "\n",
    "    zro_x = slice(0, n_x - full_shift)\n",
    "    zro_y = slice(0, n_y - full_shift)\n",
    "    zro_z = slice(0, n_z - full_shift)\n",
    "    \n",
    "    mid_x = slice(half_shift, n_x - half_shift)\n",
    "    mid_y = slice(half_shift, n_y - half_shift)\n",
    "    mid_z = slice(half_shift, n_z - half_shift)\n",
    "    \n",
    "    end_x = slice(full_shift, n_x)\n",
    "    end_y = slice(full_shift, n_y)\n",
    "    end_z = slice(full_shift, n_z)\n",
    "    \n",
    "    middle_slice = (mid_x, mid_y, mid_z)\n",
    "    \n",
    "    for x in [zro_x, mid_x, end_x]:\n",
    "        for y in [zro_y, mid_y, end_y]:\n",
    "            for z in [zro_z, mid_z, end_z]:\n",
    "                temporary_slice = (x,y,z)\n",
    "                if middle_slice == temporary_slice:\n",
    "                    pass\n",
    "                else:\n",
    "                    slices_list.append(temporary_slice)\n",
    "    \n",
    "    return middle_slice, slices_list\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a3b2a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(padded) output shape: (160, 256, 256) \n",
      "gradient (middle) shape: (158, 254, 254)\n",
      "1.720493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((160, 256, 256), (160, 256, 256), None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_quaternion_gradient_II(arr3D):\n",
    "    \"\"\"quat_grad = get_quaternion_gradient_II(arr3D)\n",
    "    \"\"\"\n",
    "    # allocate padded 3d array\n",
    "    quat_diffs = get_quat_zeros(arr3D.shape)\n",
    "    middle_slice, slices_list = get_quat_grad_middle_w_slices_list(arr3D)\n",
    "    arr3D_middle = arr3D[middle_slice]\n",
    "    \n",
    "    for shifter_slice in slices_list:\n",
    "        quat_diffs[middle_slice] += arr3D_middle - arr3D[shifter_slice]\n",
    "        \n",
    "    return quat_diffs\n",
    "\n",
    "def get_quaternion_gradient(quat_arr):\n",
    "    \"\"\" grad_arr = get_quaternion_gradient(quat_arr) \"\"\"\n",
    "    # allocate the return array - same shape as input (padded w q zeros)\n",
    "    grad_arr = get_quat_zeros(quat_arr.shape)\n",
    "    \n",
    "    # name the numbers\n",
    "    half_shift = 1\n",
    "    n_x, n_y, n_z = quat_arr.shape\n",
    "    \n",
    "    mid_x = slice(half_shift, n_x - half_shift)\n",
    "    mid_y = slice(half_shift, n_y - half_shift)\n",
    "    mid_z = slice(half_shift, n_z - half_shift)\n",
    "    mddl = (mid_x, mid_y, mid_z)\n",
    "    \n",
    "    # get the quaternion slices dictionary\n",
    "    for q_name, v in voxels_quaternion_slice_doublets_dict(n_x, n_y, n_z).items():\n",
    "        grad_arr[mddl] += (quat_arr[v['b']] - quat_arr[v['a']])\n",
    "    \n",
    "    return grad_arr\n",
    "\n",
    "\n",
    "def gradient3D(im3_arr):\n",
    "    \n",
    "    # allocate the return array - same shape as input (padded w q zeros)\n",
    "    out_arr = get_quat_zeros(im3_arr.shape)\n",
    "    \n",
    "    # name the numbers\n",
    "    half_shift = 1\n",
    "    n_x, n_y, n_z = im3_arr.shape\n",
    "    \n",
    "    mid_x = slice(half_shift, n_x - half_shift)\n",
    "    mid_y = slice(half_shift, n_y - half_shift)\n",
    "    mid_z = slice(half_shift, n_z - half_shift)\n",
    "    mddl = (mid_x, mid_y, mid_z)\n",
    "    \n",
    "    # get the quaternion slices dictionary\n",
    "    for q_name, v in voxels_quaternion_slice_doublets_dict(n_x, n_y, n_z).items():\n",
    "        out_arr[mddl] += (im3_arr[v['b']] - im3_arr[v['a']]) * v['q']\n",
    "    \n",
    "    return out_arr\n",
    "\n",
    "t0 = time.time()\n",
    "gra_im = gradient3D(nifty_image_disp)\n",
    "\n",
    "nifty_image_disp.shape, gra_im.shape, print('%0.6f'%(time.time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b74e970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, (160, 256, 256), 768, 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def im_norm(im_in):\n",
    "    im_in = im_in - im_in.min()\n",
    "    im_in = im_in / im_in.max()\n",
    "    return im_in\n",
    "\n",
    "def flat_index(float_mat):\n",
    "    \"\"\" convert the input matrix to integers from 0 to number of unique values.\n",
    "    \n",
    "    Args:\n",
    "        float_mat: two dimensional matrix.\n",
    "        \n",
    "    Return:\n",
    "        float_mat: re-enumerated so that the matrix values are all sequential ints.\n",
    "        n_colors:  number of unique values in the input / output matrix\n",
    "    \"\"\"\n",
    "    float_mat_shape = float_mat.shape\n",
    "    \n",
    "    float_mat = np.reshape(float_mat, (1, float_mat.size))\n",
    "    ixA = np.argsort(float_mat)[0]\n",
    "    \n",
    "    current_value = float_mat[0, ixA[0]]\n",
    "    \n",
    "    enumeration_value = 0\n",
    "    for ix in ixA:\n",
    "        if float_mat[0,ix] != current_value:\n",
    "            current_value = float_mat[0,ix]\n",
    "            enumeration_value += 1\n",
    "        float_mat[0,ix] = enumeration_value\n",
    "\n",
    "    float_mat = np.array(np.reshape(float_mat, float_mat_shape))\n",
    "\n",
    "    float_mat = np.int_(float_mat)\n",
    "\n",
    "    return float_mat\n",
    "\n",
    "f_mat  = flat_index(nifty_image_disp)\n",
    "type(f_mat), type(f_mat[0]), f_mat.shape, f_mat.max(), f_mat.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91a7d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bfc6e95",
   "metadata": {},
   "source": [
    "<a id='original'></a>\n",
    "[Table of Contents (page top)](#toc) <br>\n",
    "[Code](#code) <br>\n",
    "[Second Difference:](#seconddiffs) <br>\n",
    "\n",
    "\n",
    "#### Display: Original \"Input Image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2891e0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7cf0744af1429b9b45c02d078d4163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nifty_image_normalized = im_norm(nifty_image_disp)\n",
    "nifty_image_disp.shape, nifty_image_normalized.shape\n",
    "\n",
    "ipv.figure()\n",
    "ipv.volshow(nifty_image_normalized, level=[0.25, 0.75], opacity=0.03, level_width=0.1, data_min=0, data_max=1)\n",
    "ipv.view(-30, 40)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfc229a",
   "metadata": {},
   "source": [
    "\n",
    "#### display Original as ranked values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e8617f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab53a980b711425fa64831ac036c1388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nifty_image_ranked_disp = flat_index(nifty_image_disp)\n",
    "nifty_image_ranked_disp = im_norm(nifty_image_ranked_disp)\n",
    "\n",
    "ipv.figure()\n",
    "ipv.volshow(nifty_image_ranked_disp, level=[0.25, 0.75], opacity=0.03, level_width=0.1, data_min=0, data_max=1)\n",
    "ipv.view(-30, 40)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274525f9",
   "metadata": {},
   "source": [
    "#### Display Gradient Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6077f68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54f5f55519a44af934ccd5c8b555566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gra_im = gradient3D(nifty_image_disp) # as called above\n",
    "# Normalize as image\n",
    "grd_mag_im = np.abs(gra_im)\n",
    "grd_mag_im = im_norm(grd_mag_im)\n",
    "\n",
    "# display as point cloud\n",
    "ipv.figure()\n",
    "ipv.volshow(grd_mag_im, level=[0.25, 0.75], opacity=0.03, level_width=0.1, data_min=0, data_max=1)\n",
    "ipv.view(-30, 40)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f2f5d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >= 0.90           34     10485726\n",
      " >= 0.80          207     10485553\n",
      " >= 0.70          708     10485052\n",
      " >= 0.60         1530     10484230\n",
      " >= 0.50         2513     10483247\n",
      " >= 0.40         4097     10481663\n",
      " >= 0.30         7348     10478412\n",
      " >= 0.20        16108     10469652\n",
      " >= 0.10       169471     10316289\n",
      " >= 0.00     10485760            0\n"
     ]
    }
   ],
   "source": [
    "for t in [0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1, 0.0]:\n",
    "    print(' >= %0.2f %12i %12i'%(t, np.sum(grd_mag_im >= t), np.sum(grd_mag_im < t)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4513164e",
   "metadata": {},
   "source": [
    "#### Bone of Contention: 26 neighborhood 1st difference stats as selector in context of whole image visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86c57957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.181\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "quat_grad = get_quaternion_gradient_II(gra_im)\n",
    "\n",
    "tt = time.time() - t0\n",
    "print('%0.3f'%(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "add85351",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8a1d65c3644d2d9c1b3f2e9428fdba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grdII_mag_im = np.abs(quat_grad)\n",
    "grdII_mag_im = im_norm(grdII_mag_im)\n",
    "# grdII_mag_im = grdII_mag_im - grdII_mag_im.min()\n",
    "# grdII_mag_im = grdII_mag_im / grdII_mag_im.max()\n",
    "\n",
    "# display as point cloud\n",
    "ipv.figure()\n",
    "ipv.volshow(grdII_mag_im, level=[0.25, 0.75], opacity=0.03, level_width=0.1, data_min=0, data_max=1)\n",
    "ipv.view(-30, 40)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d1dc54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f5d030b",
   "metadata": {},
   "source": [
    "Berkely Psyc 214: [making and saving new images](https://bic-berkeley.github.io/psych-214-fall-2016/saving_images.html) with nibabel <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c15f42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(padded) output shape: (160, 256, 256) \n",
      "gradient (middle) shape: (158, 254, 254)\n",
      "1.716\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "grad_arr = get_quaternion_gradient(gra_im)\n",
    "print('%0.3f'%(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bb2e4a",
   "metadata": {},
   "source": [
    "<a id='seconddiffs'></a>\n",
    "[Table of Contents (page top)](#toc) <br>\n",
    "[Original Image:](#original) <br>\n",
    "[Code:](#code) <br>\n",
    "\n",
    "#### Second differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60124138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ee984a70b44c47a21aba6d87d21111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalize as image quat_grad\n",
    "# grdII_mag_im = np.abs(grad_arr)\n",
    "grdII_mag_im_old = np.abs(grad_arr)\n",
    "grdII_mag_im_old = im_norm(grdII_mag_im_old)\n",
    "\n",
    "# display as point cloud\n",
    "ipv.figure()\n",
    "ipv.volshow(grdII_mag_im_old, level=[0.25, 0.75], opacity=0.03, level_width=0.1, data_min=0, data_max=1)\n",
    "ipv.view(-30, 40)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b02134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbccc756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c7eeef4",
   "metadata": {},
   "source": [
    "##### pasted at breaktime:\n",
    "### details for nibabel saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3637cedc",
   "metadata": {},
   "source": [
    "~~~python\n",
    "# import os, time\n",
    "# import nibabel as nib\n",
    "\n",
    "#                                        Name & write\n",
    "transformed_img = nib.Nifti1Image(transformed, template_img.affine, template_img.header)\n",
    "template_img = nib.Nifti1Image(template_data, template_affine, template_img.header)\n",
    "\n",
    "nib.save(transformed_img, os.path.join(data_dir, 'XXX_transformed_NB1.nii'))\n",
    "nib.save(template_img, os.path.join(data_dir, 'XXX_template_NB1.nii'))\n",
    "\n",
    "tt = time.time() - nb_after_import_start_time\n",
    "print(f'{tt:0.3f} total run time')\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1696cb72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dadb317",
   "metadata": {},
   "source": [
    "### Thank you, Berkley Psyc 214\n",
    "~~~python\n",
    "import time, os\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "from dipy.viz import regtools\n",
    "from dipy.align.imaffine import AffineMap, MutualInformationMetric, AffineRegistration\n",
    "from dipy.align.transforms import TranslationTransform3D, RigidTransform3D, AffineTransform3D\n",
    "\n",
    "# nb_after_import_start_time = time.time()\n",
    "\n",
    "# #                                            file names full path\n",
    "# data_dir = os.path.abspath('../../../../DATA/ADNI_test')\n",
    "\n",
    "# mri_file = 'ADNI_002_S_1155_MR_Accelerated_Sagittal_MPRAGE__br_raw_20170425131856689_29_S558282_I843510.nii'\n",
    "# mri_file = os.path.join(data_dir, mri_file)\n",
    "\n",
    "# pet_file = 'ADNI_002_S_1155_PT_ADNI_Brain_PET__Raw_br_raw_20170421115500090_163_S556709_I841767.nii'\n",
    "# pet_file = os.path.join(data_dir, pet_file)\n",
    "\n",
    "# moving_img = nib.load(mri_file)\n",
    "# template_img = nib.load(pet_file)\n",
    "\n",
    "# moving_data = moving_img.get_fdata()\n",
    "# moving_affine = moving_img.affine\n",
    "\n",
    "# template_data = template_img.get_fdata()\n",
    "# template_affine = template_img.affine\n",
    "\n",
    "# identity = np.eye(4)\n",
    "# affine_map = AffineMap(identity, template_data.shape, template_affine, moving_data.shape, moving_affine)\n",
    "# resampled = affine_map.transform(moving_data)\n",
    "\n",
    "# # The mismatch metric\n",
    "# nbins = 32\n",
    "# sampling_prop = None\n",
    "# metric = MutualInformationMetric(nbins, sampling_prop)\n",
    "\n",
    "# # The optimization strategy\n",
    "# level_iters = [10, 10, 5]    # level_iters = [100, 100, 50] # 43 seconds vs \n",
    "# sigmas = [3.0, 1.0, 0.0]\n",
    "# factors = [4, 2, 1]\n",
    "\n",
    "# affreg = AffineRegistration(metric=metric, level_iters=level_iters, sigmas=sigmas, factors=factors)\n",
    "\n",
    "# transform = TranslationTransform3D()\n",
    "# params0 = None\n",
    "# translation = affreg.optimize(template_data, moving_data, transform, params0, template_affine, moving_affine)\n",
    "\n",
    "# transformed = translation.transform(moving_data)\n",
    "\n",
    "# transform = RigidTransform3D()\n",
    "# rigid = affreg.optimize(template_data, moving_data, transform, params0, template_affine, \n",
    "#                         moving_affine, starting_affine=translation.affine)\n",
    "\n",
    "# transformed = rigid.transform(moving_data)\n",
    "\n",
    "# transform = AffineTransform3D()\n",
    "\n",
    "# # Bump up the iterations to get an more exact fit\n",
    "# affreg.level_iters = [1000, 1000, 100]    # [2000, 2000, 200] # 43 sec vs dkine above\n",
    "\n",
    "# affine = affreg.optimize(template_data, moving_data, transform, params0, template_affine, \n",
    "#                          moving_affine, starting_affine=rigid.affine)\n",
    "\n",
    "# transformed = affine.transform(moving_data)\n",
    "\n",
    "\n",
    "#                                        Name & write\n",
    "transformed_img = nib.Nifti1Image(transformed, template_img.affine, template_img.header)\n",
    "template_img = nib.Nifti1Image(template_data, template_affine, template_img.header)\n",
    "\n",
    "nib.save(transformed_img, os.path.join(data_dir, 'XXX_transformed_NB1.nii'))\n",
    "nib.save(template_img, os.path.join(data_dir, 'XXX_template_NB1.nii'))\n",
    "\n",
    "tt = time.time() - nb_after_import_start_time\n",
    "print(f'{tt:0.3f} total run time')\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd48df0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env] *",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
