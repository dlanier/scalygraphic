{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e7cc50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96fbcee",
   "metadata": {},
   "source": [
    "<a id='toc'></a>\n",
    "### Notebook Table of Contents\n",
    "[Imports](#imports) <br>\n",
    "[Original Image:](#original) <br>\n",
    "[Code:](#code) <br>\n",
    "[Second Difference:](#seconddiffs) <br>\n",
    "****\n",
    "# Quaternions as data-type, 3D Gradient operations\n",
    "Free Unified Rendering in Python [pypi FURY](https://pypi.org/project/fury/), [](), [](), []() <br>\n",
    "[Brain Extraction Tool](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BET) <br>\n",
    "Robust Brain Extraction [ROBEX](https://www.nitrc.org/projects/robex) <br>\n",
    "****\n",
    "Berkeley Psyc 214 fall 2016 [dipy](https://bic-berkeley.github.io/psych-214-fall-2016/dipy_registration.html) <br>\n",
    "dipy: [tutorials](https://dipy.org/tutorials/), [](), [](), []() <br>\n",
    "[Open Neuro](https://openneuro.org/) <br>\n",
    "[Oxford FSL](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki) <br>\n",
    "****\n",
    "****\n",
    "[TorchIO dakine](https://torchio.readthedocs.io/index.html) <br>\n",
    "\n",
    "~~~text\n",
    "        HAL seek: ADNI 3 dataset\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8d1040",
   "metadata": {},
   "source": [
    "****\n",
    "[Table of Contents (page top)](#toc) <br>\n",
    "### Import \n",
    "#### modules, packages, whatever, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b7e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e415ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-180., -140., -100.,  -60.,  -20.,   20.,   60.,  100.,  140.,\n",
       "        180.,  220.,  260.,  300.,  340.,  380.,  420.,  460.,  500.,\n",
       "        540.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "phase = np.linspace(0, np.pi, num=5)\n",
    "phase[3:] += np.pi\n",
    "phase\n",
    "# array([ 0.        ,  0.78539816,  1.57079633,  5.49778714,  6.28318531]) # may vary\n",
    "\n",
    "np.unwrap(phase)\n",
    "# array([ 0.        ,  0.78539816,  1.57079633, -0.78539816,  0.        ]) # may vary\n",
    "\n",
    "np.unwrap([0, 1, 2, -1, 0], period=4)\n",
    "# array([0, 1, 2, 3, 4])\n",
    "\n",
    "np.unwrap([ 1, 2, 3, 4, 5, 6, 1, 2, 3], period=6)\n",
    "# array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "np.unwrap([2, 3, 4, 5, 2, 3, 4, 5], period=4)\n",
    "# array([2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "\n",
    "phase_deg = np.mod(np.linspace(0 ,720, 19), 360) - 180\n",
    "np.unwrap(phase_deg, period=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28563804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7f38d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.78539816, 1.57079633, 5.49778714, 6.28318531])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "phase = np.linspace(0, np.pi, num=5)\n",
    "phase[3:] += np.pi\n",
    "phase\n",
    "# array([ 0.        ,  0.78539816,  1.57079633,  5.49778714,  6.28318531]) # may vary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69464bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.78539816,  1.57079633, -0.78539816,  0.        ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unwrap(phase)\n",
    "# array([ 0.        ,  0.78539816,  1.57079633, -0.78539816,  0.        ]) # may vary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "136d931d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2., -1.,  0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unwrap([0, 1, 2, -1, 0], discont=4)\n",
    "# array([0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f49ab3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unwrap([ 1, 2, 3, 4, 5, 6, 1, 2, 3], period=6)\n",
    "# array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f502d94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unwrap([2, 3, 4, 5, 2, 3, 4, 5], period=4)\n",
    "# array([2, 3, 4, 5, 6, 7, 8, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba111364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-180., -140., -100.,  -60.,  -20.,   20.,   60.,  100.,  140.,\n",
       "        180.,  220.,  260.,  300.,  340.,  380.,  420.,  460.,  500.,\n",
       "        540.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "phase_deg = np.mod(np.linspace(0 ,720, 19), 360) - 180\n",
    "np.unwrap(phase_deg, period=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddeb3900",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                            else nibabel writes in red\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#                                            demo examination tools\n",
    "import time, os, sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import quaternion\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import nibabel as nib\n",
    "import ipyvolume as ipv\n",
    "\n",
    "#                                            basic transform demo imports\n",
    "from dipy.viz import regtools\n",
    "from dipy.align.imaffine import AffineMap, MutualInformationMetric, AffineRegistration\n",
    "from dipy.align.transforms import TranslationTransform3D, RigidTransform3D, AffineTransform3D\n",
    "\n",
    "#                                            Non-Linear transform demo imports\n",
    "from dipy.align.imwarp import SymmetricDiffeomorphicRegistration\n",
    "from dipy.align.imwarp import DiffeomorphicMap\n",
    "from dipy.align.metrics import CCMetric\n",
    "\n",
    "nb_after_import_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86b5a99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ANDI 3 MR - Flobetapir search Oct 2021_002.xlsx',\n",
       " '.DS_Store',\n",
       " 'MR and 18F PET - Jan 27 2022.xlsx',\n",
       " 'ADNI3_PET_AV45.xlsx',\n",
       " 'ANDI 3 MR - Flobetapir search Oct 2021.xlsx',\n",
       " 'ADNI',\n",
       " 'Meta_ADNI3_3T_3D_AV45']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adni_dir = os.path.abspath('../../../../DATA/Kiaran_ADNI')\n",
    "os.listdir(adni_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b2362aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found:\n",
      "1094596 dicom\n",
      "9522 nifti\n",
      " 1104118 total files 9.314695\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "file_types = ['.nii', '.dcm']\n",
    "adni_image_files_dict = {}\n",
    "nifti_files = []\n",
    "dicom_files = []\n",
    "\n",
    "for d, dl, fl in os.walk(adni_dir):\n",
    "    for f in fl:\n",
    "        f_ext = os.path.splitext(f)[1]\n",
    "        if f_ext in file_types:\n",
    "            full_file = os.path.join(d, f)\n",
    "            if f in adni_image_files_dict:\n",
    "                print('Fooey: duplicates', os.path.join(d, f))\n",
    "            adni_image_files_dict[f] = full_file\n",
    "            if f_ext == '.nii':\n",
    "                nifti_files.append(full_file)\n",
    "            elif f_ext == '.dcm':\n",
    "                dicom_files.append(full_file)\n",
    "                \n",
    "tt = time.time() - t_start\n",
    "\n",
    "print('found:\\n%03i dicom\\n%03i nifti\\n %i total files %0.6f'%(len(dicom_files), \n",
    "                                                               len(nifti_files), \n",
    "                                                               len(adni_image_files_dict),\n",
    "                                                               tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7a5a47",
   "metadata": {},
   "source": [
    "****\n",
    "<a id='original'></a>\n",
    "[Table of Contents (page top)](#toc) <br>\n",
    "[Code](#code) <br>\n",
    "[Second Difference:](#seconddiffs) <br>\n",
    "\n",
    "\n",
    "#### Image file select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36655f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2a96488b0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skimage import io\n",
    "import numpy as np\n",
    "data=np.random.randn(5,2)\n",
    "io.imshow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c4ffa29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.int16'> 0\n",
      "1 <class 'numpy.memmap'> (182, 256, 256) <class 'numpy.int16'> 0\n",
      "2 <class 'numpy.memmap'> (64, 64, 64, 2) <class 'numpy.memmap'> [8 7]\n",
      "3 <class 'numpy.memmap'> (162, 162, 1) <class 'numpy.int16'> 0\n",
      "4 <class 'numpy.memmap'> (208, 240, 256) <class 'numpy.int16'> 0\n",
      "5 <class 'numpy.memmap'> (128, 128, 46) <class 'numpy.float32'> 0.0\n",
      "6 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.int16'> 0\n",
      "7 <class 'numpy.ndarray'> (80, 80, 52) <class 'numpy.float64'> -3.141592502593994\n",
      "8 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.int16'> 0\n",
      "9 <class 'numpy.memmap'> (162, 162, 1) <class 'numpy.int16'> 0\n",
      "10 <class 'numpy.memmap'> (64, 64, 64, 2) <class 'numpy.memmap'> [4 6]\n",
      "11 <class 'numpy.memmap'> (128, 128, 32, 20) <class 'numpy.memmap'> [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "12 <class 'numpy.ndarray'> (96, 96, 40) <class 'numpy.float64'> 0.0\n",
      "13 <class 'numpy.memmap'> (162, 162, 1) <class 'numpy.int16'> 0\n",
      "14 <class 'numpy.ndarray'> (80, 80, 52) <class 'numpy.float64'> 0.0\n",
      "15 <class 'numpy.ndarray'> (80, 80, 52) <class 'numpy.float64'> 0.0\n",
      "16 <class 'numpy.memmap'> (64, 64, 40, 2) <class 'numpy.memmap'> [0 0]\n",
      "17 <class 'numpy.memmap'> (128, 128, 40) <class 'numpy.int16'> 0\n",
      "18 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.int16'> 0\n",
      "19 <class 'numpy.ndarray'> (128, 128, 90, 4) <class 'numpy.ndarray'> [0. 0. 0. 0.]\n",
      "20 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.int16'> 0\n",
      "21 <class 'numpy.memmap'> (208, 240, 256) <class 'numpy.int16'> 0\n",
      "22 <class 'numpy.memmap'> (128, 128, 40) <class 'numpy.int16'> 0\n",
      "23 <class 'numpy.memmap'> (162, 162, 1) <class 'numpy.int16'> 0\n",
      "24 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.int16'> 0\n",
      "25 <class 'numpy.memmap'> (64, 64, 40, 2) <class 'numpy.memmap'> [0 0]\n",
      "26 <class 'numpy.ndarray'> (160, 256, 256) <class 'numpy.float64'> 0.0\n",
      "27 <class 'numpy.memmap'> (128, 128, 32, 20) <class 'numpy.memmap'> [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "28 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.int16'> 0\n",
      "29 <class 'numpy.memmap'> (230, 230, 175) <class 'numpy.int16'> 0\n",
      "30 <class 'numpy.ndarray'> (80, 80, 52) <class 'numpy.float64'> 0.0\n",
      "31 <class 'numpy.memmap'> (182, 256, 256) <class 'numpy.int16'> 0\n",
      "32 <class 'numpy.ndarray'> (211, 256, 256) <class 'numpy.float64'> 0.0\n",
      "33 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.int16'> 0\n",
      "34 <class 'numpy.ndarray'> (80, 80, 52) <class 'numpy.float64'> 0.0\n",
      "35 <class 'numpy.memmap'> (160, 256, 256) <class 'numpy.int16'> 0\n",
      "36 <class 'numpy.memmap'> (182, 256, 256) <class 'numpy.int16'> 0\n",
      "37 <class 'numpy.memmap'> (128, 128, 40) <class 'numpy.int16'> 0\n",
      "38 <class 'numpy.memmap'> (128, 128, 40) <class 'numpy.int16'> 0\n",
      "39 <class 'numpy.memmap'> (162, 162, 1) <class 'numpy.int16'> 0\n"
     ]
    }
   ],
   "source": [
    "goodies = [0, 4]\n",
    "for i in range(40):\n",
    "    full_file = nifti_files[i]\n",
    "    # im_data = pydicom.dcmread(full_file).pixel_array\n",
    "    nifty_image = nib.load(full_file)\n",
    "    nifty_image_disp = nifty_image.get_data()\n",
    "    print(i, type(nifty_image_disp), nifty_image_disp.shape, \n",
    "          type(nifty_image_disp[0,0,0]), nifty_image_disp[0,0,0])\n",
    "    \n",
    "# pick one here:\n",
    "full_file = nifti_files[0]\n",
    "nifty_image = nib.load(full_file)\n",
    "nifty_image_disp = nifty_image.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d373824f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected file: /Users/daniellanier/DATA/Kiaran_ADNI/ADNI/_Sagittal_3D_FLAIR_20210621104220_3.nii\n",
      "Opened as type <class 'numpy.memmap'> size: (160, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "print('selected file: %s\\nOpened as type %s size:'%(full_file, type(nifty_image_disp)), nifty_image_disp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e7476c",
   "metadata": {},
   "source": [
    "<a id='code'></a>\n",
    "[Table of Contents (page top)](#toc) <br>\n",
    "[Original Image:](#original) <br>\n",
    "\n",
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a36d0316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quat_zeros(arr_size):\n",
    "    return np.ones(arr_size) * np.quaternion(1,0,0,0)\n",
    "\n",
    "def get_quat_ones(arr_size):\n",
    "    return np.ones(arr_size) * np.quaternion(1,1,1,1)\n",
    "\n",
    "Q_ID_dict = {'w': np.quaternion(1,0,0,0), \n",
    "             'i': np.quaternion(0,1,0,0), \n",
    "             'j': np.quaternion(0,0,1,0), \n",
    "             'k': np.quaternion(0,0,0,1)}\n",
    "\n",
    "def voxels_quaternion_slice_doublets_dict(n_x, n_y, n_z):\n",
    "    # width of central difference in voxels:\n",
    "    qdd = 13                              # 13 quaternions - magnitude divisor\n",
    "    half_shift = 1                        # 1/2 central difference accross voxel\n",
    "    n_shift = half_shift * 2              # indexing central difference for any direction\n",
    "\n",
    "    #     n_x, n_y, n_z = im_arr.shape\n",
    "    #     im_grad_arr = get_quat_ones(im_arr.shape)\n",
    "    im_grad_arr = get_quat_ones((n_x, n_y, n_z))\n",
    "\n",
    "    mid_x = slice(half_shift, n_x - half_shift)\n",
    "    mid_y = slice(half_shift, n_y - half_shift)\n",
    "    mid_z = slice(half_shift, n_z - half_shift)\n",
    "    mddl = (mid_x, mid_y, mid_z)\n",
    "\n",
    "    print('(padded) output shape:', im_grad_arr.shape, '\\ngradient (middle) shape:', im_grad_arr[mddl].shape)\n",
    "    \"\"\"\n",
    "                for i in q_ix:\n",
    "                    G += (b_i - a_i) * q_i    \n",
    "\n",
    "    iterate: each quaternion direction with slices: I[b_slice[x], b_slice[y], b_slice[z]] - I[a_slize[x]...]\n",
    "    \"\"\"\n",
    "\n",
    "    #                                       Vector ~ Slice-a, Slice-b\n",
    "    #                                       on-axis: x, x & y\n",
    "    qx = Q_ID_dict['i']\n",
    "    qx_a = (slice(0, n_x - n_shift), mid_y, mid_z)\n",
    "    qx_b = (slice(n_shift, n_x), mid_y, mid_z)\n",
    "\n",
    "    qy = Q_ID_dict['j']\n",
    "    qy_a = (mid_x, slice(0, n_y - n_shift), mid_z)\n",
    "    qy_b = (mid_x, slice(n_shift, n_y), mid_z)\n",
    "\n",
    "    qz = Q_ID_dict['k']\n",
    "    qz_a = (mid_x, mid_y, slice(0, n_z - n_shift))\n",
    "    qz_b = (mid_x, mid_y, slice(n_shift, n_z))\n",
    "\n",
    "\n",
    "    #                                       in-plane: x+y, x-y, y+z, y-z, z+y\n",
    "    qxy = qx + qy\n",
    "    qxy_a = (slice(0, n_x - n_shift), slice(0, n_y - n_shift), mid_z)\n",
    "    qxy_b = (slice(n_shift, n_x), slice(n_shift, n_y), mid_z)\n",
    "\n",
    "    qx_y = qx - qy\n",
    "    qx_y_a = (slice(0, n_x - n_shift), slice(n_shift, n_y), mid_z)\n",
    "    qx_y_b = (slice(n_shift, n_x), slice(0, n_y - n_shift), mid_z)\n",
    "\n",
    "    qyz = qy + qz\n",
    "    qyz_a = (mid_x, slice(0, n_y - n_shift), slice(0, n_z - n_shift))\n",
    "    qyz_b = (mid_x, slice(n_shift, n_y), slice(n_shift, n_z))\n",
    "\n",
    "    qy_z = qy - qz\n",
    "    qy_z_a = (mid_x, slice(0, n_y - n_shift), slice(n_shift, n_z))\n",
    "    qy_z_b = (mid_x, slice(n_shift, n_y), slice(0, n_z - n_shift))\n",
    "\n",
    "    qzx = qz + qx\n",
    "    qzx_a = (slice(0, n_x - n_shift), mid_y, slice(0, n_z - n_shift))\n",
    "    qzx_b = (slice(n_shift, n_x), mid_y, slice(n_shift, n_z))\n",
    "\n",
    "    qz_x = qz - qx\n",
    "    qx_z_a = (slice(n_shift, n_x), mid_y, slice(0, n_z - n_shift))\n",
    "    qx_z_b = (slice(0, n_x - n_shift), mid_y, slice(n_shift, n_z))\n",
    "\n",
    "\n",
    "    # x, y, z Totally positive\n",
    "    qxyz = qx + qy + qz\n",
    "    qxyz_a = (slice(0, n_x - n_shift), slice(0, n_y - n_shift), slice(0, n_z - n_shift))\n",
    "    qxyz_b = (slice(n_shift, n_x), slice(n_shift, n_y), slice(n_shift, n_z))\n",
    "\n",
    "    # -x, y, z\n",
    "    q_xyz = qy + qz - qx\n",
    "    q_xyz_a = (slice(n_shift, n_x), slice(0, n_y - n_shift), slice(0, n_z - n_shift))\n",
    "    q_xyz_b = (slice(0, n_x - n_shift), slice(n_shift, n_y), slice(n_shift, n_z))\n",
    "\n",
    "    # x, -y, z\n",
    "    qx_yz = qx - qy + qz\n",
    "    qx_yz_a = (slice(0, n_x - n_shift), slice(n_shift, n_y), slice(0, n_z - n_shift))\n",
    "    qx_yz_b = (slice(n_shift, n_x), slice(0, n_y - n_shift), slice(n_shift, n_z))\n",
    "\n",
    "    # x, y, -z\n",
    "    qxy_z = qx + qy - qz\n",
    "    qxy_z_a = (slice(0, n_x - n_shift), slice(0, n_y - n_shift), slice(n_shift, n_z))\n",
    "    qxy_z_b = (slice(n_shift, n_x), slice(n_shift, n_y), slice(0, n_z - n_shift))\n",
    "\n",
    "\n",
    "    vox_pd_vex = {'qx': {'q': qx / qdd, 'a': qx_a, 'b': qx_b}, \n",
    "                  'qy': {'q': qy / qdd, 'a': qy_a, 'b': qy_b}, \n",
    "                  'qz': {'q': qz / qdd, 'a': qz_a, 'b': qz_b},  \n",
    "                  'qxy': {'q': qxy / qdd, 'a': qxy_a, 'b': qxy_b}, \n",
    "                  'qx_y': {'q': qx_y / qdd, 'a': qx_y_a, 'b': qx_y_b}, \n",
    "                  'qyz': {'q': qyz / qdd, 'a': qyz_a, 'b': qyz_b}, \n",
    "                  'qy_z': {'q': qy_z / qdd, 'a': qy_z_a, 'b': qy_z_b}, \n",
    "                  'qzx': {'q': qzx / qdd, 'a': qzx_a, 'b': qzx_b},  \n",
    "                  'qz_x': {'q': qz_x / qdd, 'a': qx_z_a, 'b': qx_z_b}, \n",
    "                  'qxyz': {'q': qxyz / qdd, 'a': qxyz_a, 'b': qxyz_b}, \n",
    "                  'q_xyz': {'q': q_xyz / qdd, 'a': q_xyz_a, 'b': q_xyz_b}, \n",
    "                  'qx_yz': {'q': qx_yz / qdd, 'a': qx_yz_a, 'b': qx_yz_b},\n",
    "                  'qxy_z': {'q': qxy_z / qdd, 'a': qxy_z_a, 'b': qxy_z_b} }\n",
    "    \n",
    "    return vox_pd_vex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dd8552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quat_grad_middle_w_slices_list(arr3D):\n",
    "    \"\"\"middle_slice, slices_list = get_quat_grad_middle_w_slices_list(arr3D)\n",
    "    \"\"\"\n",
    "    slices_list = []\n",
    "    n_x, n_y, n_z = arr3D.shape\n",
    "    \n",
    "    # name the numbers\n",
    "    half_shift = 1\n",
    "    full_shift = 2\n",
    "\n",
    "    zro_x = slice(0, n_x - full_shift)\n",
    "    zro_y = slice(0, n_y - full_shift)\n",
    "    zro_z = slice(0, n_z - full_shift)\n",
    "    \n",
    "    mid_x = slice(half_shift, n_x - half_shift)\n",
    "    mid_y = slice(half_shift, n_y - half_shift)\n",
    "    mid_z = slice(half_shift, n_z - half_shift)\n",
    "    \n",
    "    end_x = slice(full_shift, n_x)\n",
    "    end_y = slice(full_shift, n_y)\n",
    "    end_z = slice(full_shift, n_z)\n",
    "    \n",
    "    middle_slice = (mid_x, mid_y, mid_z)\n",
    "    \n",
    "    for x in [zro_x, mid_x, end_x]:\n",
    "        for y in [zro_y, mid_y, end_y]:\n",
    "            for z in [zro_z, mid_z, end_z]:\n",
    "                temporary_slice = (x,y,z)\n",
    "                if middle_slice == temporary_slice:\n",
    "                    pass\n",
    "                else:\n",
    "                    slices_list.append(temporary_slice)\n",
    "    \n",
    "    return middle_slice, slices_list\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a3b2a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(padded) output shape: (160, 256, 256) \n",
      "gradient (middle) shape: (158, 254, 254)\n",
      "1.730228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((160, 256, 256), (160, 256, 256), None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_quaternion_gradient_II(arr3D):\n",
    "    \"\"\"quat_grad = get_quaternion_gradient_II(arr3D)\n",
    "    \"\"\"\n",
    "    # allocate padded 3d array\n",
    "    quat_diffs = get_quat_zeros(arr3D.shape)\n",
    "    middle_slice, slices_list = get_quat_grad_middle_w_slices_list(arr3D)\n",
    "    arr3D_middle = arr3D[middle_slice]\n",
    "    \n",
    "    for shifter_slice in slices_list:\n",
    "        quat_diffs[middle_slice] += arr3D_middle - arr3D[shifter_slice]\n",
    "        \n",
    "    return quat_diffs\n",
    "\n",
    "def get_quaternion_gradient(quat_arr):\n",
    "    \"\"\" grad_arr = get_quaternion_gradient(quat_arr) \"\"\"\n",
    "    # allocate the return array - same shape as input (padded w q zeros)\n",
    "    grad_arr = get_quat_zeros(quat_arr.shape)\n",
    "    \n",
    "    # name the numbers\n",
    "    half_shift = 1\n",
    "    n_x, n_y, n_z = quat_arr.shape\n",
    "    \n",
    "    mid_x = slice(half_shift, n_x - half_shift)\n",
    "    mid_y = slice(half_shift, n_y - half_shift)\n",
    "    mid_z = slice(half_shift, n_z - half_shift)\n",
    "    mddl = (mid_x, mid_y, mid_z)\n",
    "    \n",
    "    # get the quaternion slices dictionary\n",
    "    for q_name, v in voxels_quaternion_slice_doublets_dict(n_x, n_y, n_z).items():\n",
    "        grad_arr[mddl] += (quat_arr[v['b']] - quat_arr[v['a']])\n",
    "    \n",
    "    return grad_arr\n",
    "\n",
    "\n",
    "def gradient3D(im3_arr):\n",
    "    \n",
    "    # allocate the return array - same shape as input (padded w q zeros)\n",
    "    out_arr = get_quat_zeros(im3_arr.shape)\n",
    "    \n",
    "    # name the numbers\n",
    "    half_shift = 1\n",
    "    n_x, n_y, n_z = im3_arr.shape\n",
    "    \n",
    "    mid_x = slice(half_shift, n_x - half_shift)\n",
    "    mid_y = slice(half_shift, n_y - half_shift)\n",
    "    mid_z = slice(half_shift, n_z - half_shift)\n",
    "    mddl = (mid_x, mid_y, mid_z)\n",
    "    \n",
    "    # get the quaternion slices dictionary\n",
    "    for q_name, v in voxels_quaternion_slice_doublets_dict(n_x, n_y, n_z).items():\n",
    "        out_arr[mddl] += (im3_arr[v['b']] - im3_arr[v['a']]) * v['q']\n",
    "    \n",
    "    return out_arr\n",
    "\n",
    "t0 = time.time()\n",
    "gra_im = gradient3D(nifty_image_disp)\n",
    "\n",
    "nifty_image_disp.shape, gra_im.shape, print('%0.6f'%(time.time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b74e970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, (160, 256, 256), 768, 0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def im_norm(im_in):\n",
    "    im_in = im_in - im_in.min()\n",
    "    im_in = im_in / im_in.max()\n",
    "    return im_in\n",
    "\n",
    "def flat_index(float_mat):\n",
    "    \"\"\" convert the input matrix to integers from 0 to number of unique values.\n",
    "    \n",
    "    Args:\n",
    "        float_mat: two dimensional matrix.\n",
    "        \n",
    "    Return:\n",
    "        float_mat: re-enumerated so that the matrix values are all sequential ints.\n",
    "        n_colors:  number of unique values in the input / output matrix\n",
    "    \"\"\"\n",
    "    float_mat_shape = float_mat.shape\n",
    "    \n",
    "    float_mat = np.reshape(float_mat, (1, float_mat.size))\n",
    "    ixA = np.argsort(float_mat)[0]\n",
    "    \n",
    "    current_value = float_mat[0, ixA[0]]\n",
    "    \n",
    "    enumeration_value = 0\n",
    "    for ix in ixA:\n",
    "        if float_mat[0,ix] != current_value:\n",
    "            current_value = float_mat[0,ix]\n",
    "            enumeration_value += 1\n",
    "        float_mat[0,ix] = enumeration_value\n",
    "\n",
    "    float_mat = np.array(np.reshape(float_mat, float_mat_shape))\n",
    "\n",
    "    float_mat = np.int_(float_mat)\n",
    "\n",
    "    return float_mat\n",
    "\n",
    "f_mat  = flat_index(nifty_image_disp)\n",
    "type(f_mat), type(f_mat[0]), f_mat.shape, f_mat.max(), f_mat.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91a7d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bfc6e95",
   "metadata": {},
   "source": [
    "<a id='original'></a>\n",
    "[Table of Contents (page top)](#toc) <br>\n",
    "[Code](#code) <br>\n",
    "[Second Difference:](#seconddiffs) <br>\n",
    "\n",
    "\n",
    "#### Display: Original \"Input Image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2891e0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5523c9d617ee472aafd62c19494c257c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nifty_image_normalized = im_norm(nifty_image_disp)\n",
    "nifty_image_disp.shape, nifty_image_normalized.shape\n",
    "\n",
    "ipv.figure()\n",
    "ipv.volshow(nifty_image_normalized, level=[0.25, 0.75], opacity=0.03, level_width=0.1, data_min=0, data_max=1)\n",
    "ipv.view(-30, 40)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfc229a",
   "metadata": {},
   "source": [
    "\n",
    "#### display Original as ranked values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e8617f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8ae3a5f2654019a20b5f45d42e283f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nifty_image_ranked_disp = flat_index(nifty_image_disp)\n",
    "nifty_image_ranked_disp = im_norm(nifty_image_ranked_disp)\n",
    "\n",
    "ipv.figure()\n",
    "ipv.volshow(nifty_image_ranked_disp, level=[0.25, 0.75], opacity=0.03, level_width=0.1, data_min=0, data_max=1)\n",
    "ipv.view(-30, 40)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274525f9",
   "metadata": {},
   "source": [
    "#### Display Gradient Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6077f68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8584d95f359a47fcbafe9c82da6b116a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gra_im = gradient3D(nifty_image_disp) # as called above\n",
    "# Normalize as image\n",
    "grd_mag_im = np.abs(gra_im)\n",
    "grd_mag_im = im_norm(grd_mag_im)\n",
    "\n",
    "# display as point cloud\n",
    "ipv.figure()\n",
    "ipv.volshow(grd_mag_im, level=[0.25, 0.75], opacity=0.03, level_width=0.1, data_min=0, data_max=1)\n",
    "ipv.view(-30, 40)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f2f5d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >= 0.90           34     10485726\n",
      " >= 0.80          207     10485553\n",
      " >= 0.70          708     10485052\n",
      " >= 0.60         1530     10484230\n",
      " >= 0.50         2513     10483247\n",
      " >= 0.40         4097     10481663\n",
      " >= 0.30         7348     10478412\n",
      " >= 0.20        16108     10469652\n",
      " >= 0.10       169471     10316289\n",
      " >= 0.00     10485760            0\n"
     ]
    }
   ],
   "source": [
    "for t in [0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1, 0.0]:\n",
    "    print(' >= %0.2f %12i %12i'%(t, np.sum(grd_mag_im >= t), np.sum(grd_mag_im < t)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4513164e",
   "metadata": {},
   "source": [
    "#### Bone of Contention: 26 neighborhood 1st difference stats as selector in context of whole image visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86c57957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.182\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "quat_grad = get_quaternion_gradient_II(gra_im)\n",
    "\n",
    "tt = time.time() - t0\n",
    "print('%0.3f'%(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "add85351",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14733c89f4f4519b4911dfee730edac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grdII_mag_im = np.abs(quat_grad)\n",
    "grdII_mag_im = im_norm(grdII_mag_im)\n",
    "# grdII_mag_im = grdII_mag_im - grdII_mag_im.min()\n",
    "# grdII_mag_im = grdII_mag_im / grdII_mag_im.max()\n",
    "\n",
    "# display as point cloud\n",
    "ipv.figure()\n",
    "ipv.volshow(grdII_mag_im, level=[0.25, 0.75], opacity=0.03, level_width=0.1, data_min=0, data_max=1)\n",
    "ipv.view(-30, 40)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d1dc54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f5d030b",
   "metadata": {},
   "source": [
    "Berkely Psyc 214: [making and saving new images](https://bic-berkeley.github.io/psych-214-fall-2016/saving_images.html) with nibabel <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c15f42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(padded) output shape: (160, 256, 256) \n",
      "gradient (middle) shape: (158, 254, 254)\n",
      "1.771\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "grad_arr = get_quaternion_gradient(gra_im)\n",
    "print('%0.3f'%(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bb2e4a",
   "metadata": {},
   "source": [
    "<a id='seconddiffs'></a>\n",
    "[Table of Contents (page top)](#toc) <br>\n",
    "[Original Image:](#original) <br>\n",
    "[Code:](#code) <br>\n",
    "\n",
    "#### Second differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60124138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3dfecdbcdeb4aacafb5911543ce798a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Label(value='levels:'), FloatSlider(value=0.25, max=1.0, step=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalize as image quat_grad\n",
    "# grdII_mag_im = np.abs(grad_arr)\n",
    "grdII_mag_im_old = np.abs(grad_arr)\n",
    "grdII_mag_im_old = im_norm(grdII_mag_im_old)\n",
    "\n",
    "# display as point cloud\n",
    "ipv.figure()\n",
    "ipv.volshow(grdII_mag_im_old, level=[0.25, 0.75], opacity=0.03, level_width=0.1, data_min=0, data_max=1)\n",
    "ipv.view(-30, 40)\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b02134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbccc756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c7eeef4",
   "metadata": {},
   "source": [
    "##### pasted at breaktime:\n",
    "### details for nibabel saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3637cedc",
   "metadata": {},
   "source": [
    "~~~python\n",
    "# import os, time\n",
    "# import nibabel as nib\n",
    "\n",
    "#                                        Name & write\n",
    "transformed_img = nib.Nifti1Image(transformed, template_img.affine, template_img.header)\n",
    "template_img = nib.Nifti1Image(template_data, template_affine, template_img.header)\n",
    "\n",
    "nib.save(transformed_img, os.path.join(data_dir, 'XXX_transformed_NB1.nii'))\n",
    "nib.save(template_img, os.path.join(data_dir, 'XXX_template_NB1.nii'))\n",
    "\n",
    "tt = time.time() - nb_after_import_start_time\n",
    "print(f'{tt:0.3f} total run time')\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1696cb72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dadb317",
   "metadata": {},
   "source": [
    "### Thank you, Berkley Psyc 214\n",
    "~~~python\n",
    "import time, os\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "from dipy.viz import regtools\n",
    "from dipy.align.imaffine import AffineMap, MutualInformationMetric, AffineRegistration\n",
    "from dipy.align.transforms import TranslationTransform3D, RigidTransform3D, AffineTransform3D\n",
    "\n",
    "# nb_after_import_start_time = time.time()\n",
    "\n",
    "# #                                            file names full path\n",
    "# data_dir = os.path.abspath('../../../../DATA/ADNI_test')\n",
    "\n",
    "# mri_file = 'ADNI_002_S_1155_MR_Accelerated_Sagittal_MPRAGE__br_raw_20170425131856689_29_S558282_I843510.nii'\n",
    "# mri_file = os.path.join(data_dir, mri_file)\n",
    "\n",
    "# pet_file = 'ADNI_002_S_1155_PT_ADNI_Brain_PET__Raw_br_raw_20170421115500090_163_S556709_I841767.nii'\n",
    "# pet_file = os.path.join(data_dir, pet_file)\n",
    "\n",
    "# moving_img = nib.load(mri_file)\n",
    "# template_img = nib.load(pet_file)\n",
    "\n",
    "# moving_data = moving_img.get_fdata()\n",
    "# moving_affine = moving_img.affine\n",
    "\n",
    "# template_data = template_img.get_fdata()\n",
    "# template_affine = template_img.affine\n",
    "\n",
    "# identity = np.eye(4)\n",
    "# affine_map = AffineMap(identity, template_data.shape, template_affine, moving_data.shape, moving_affine)\n",
    "# resampled = affine_map.transform(moving_data)\n",
    "\n",
    "# # The mismatch metric\n",
    "# nbins = 32\n",
    "# sampling_prop = None\n",
    "# metric = MutualInformationMetric(nbins, sampling_prop)\n",
    "\n",
    "# # The optimization strategy\n",
    "# level_iters = [10, 10, 5]    # level_iters = [100, 100, 50] # 43 seconds vs \n",
    "# sigmas = [3.0, 1.0, 0.0]\n",
    "# factors = [4, 2, 1]\n",
    "\n",
    "# affreg = AffineRegistration(metric=metric, level_iters=level_iters, sigmas=sigmas, factors=factors)\n",
    "\n",
    "# transform = TranslationTransform3D()\n",
    "# params0 = None\n",
    "# translation = affreg.optimize(template_data, moving_data, transform, params0, template_affine, moving_affine)\n",
    "\n",
    "# transformed = translation.transform(moving_data)\n",
    "\n",
    "# transform = RigidTransform3D()\n",
    "# rigid = affreg.optimize(template_data, moving_data, transform, params0, template_affine, \n",
    "#                         moving_affine, starting_affine=translation.affine)\n",
    "\n",
    "# transformed = rigid.transform(moving_data)\n",
    "\n",
    "# transform = AffineTransform3D()\n",
    "\n",
    "# # Bump up the iterations to get an more exact fit\n",
    "# affreg.level_iters = [1000, 1000, 100]    # [2000, 2000, 200] # 43 sec vs dkine above\n",
    "\n",
    "# affine = affreg.optimize(template_data, moving_data, transform, params0, template_affine, \n",
    "#                          moving_affine, starting_affine=rigid.affine)\n",
    "\n",
    "# transformed = affine.transform(moving_data)\n",
    "\n",
    "\n",
    "#                                        Name & write\n",
    "transformed_img = nib.Nifti1Image(transformed, template_img.affine, template_img.header)\n",
    "template_img = nib.Nifti1Image(template_data, template_affine, template_img.header)\n",
    "\n",
    "nib.save(transformed_img, os.path.join(data_dir, 'XXX_transformed_NB1.nii'))\n",
    "nib.save(template_img, os.path.join(data_dir, 'XXX_template_NB1.nii'))\n",
    "\n",
    "tt = time.time() - nb_after_import_start_time\n",
    "print(f'{tt:0.3f} total run time')\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd48df0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env] *",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
