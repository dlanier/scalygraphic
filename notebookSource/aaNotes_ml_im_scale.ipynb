{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Scaling with Machine Learning\n",
    "## Inputs:\n",
    "    1) Number of image pairs\n",
    "    2) dictionary of {size_label_A: [pixels_high, pixels_wide], \n",
    "                      size_label_B: [pixels_high, pixels_wide]}\n",
    "    3) run directory\n",
    "    4) output directory\n",
    "    5) existing sets parameters.json (None for first run)\n",
    "***\n",
    "## Parameters to generate a set of images for train-test-validate\n",
    "    * Over all parameters\n",
    "        * number of image sets\n",
    "        * sizes dict {name1: [h, w], name2: [h, w],...}\n",
    "        * run-limits {escape_boundry: diagonal_multiplier, max_iterations: int}\n",
    "        * coloring scheme - perhaps a function\n",
    "        * output file format\n",
    "        * ouput file naming format\n",
    "    * File system\n",
    "        * output directory {train: path, test: path, validate: path}\n",
    "        * run-log location\n",
    "    * Stocastic Choices:\n",
    "        * hashed dictionary - to reject duplicate images\n",
    "        * equation\n",
    "            * parameters\n",
    "        * rotation \n",
    "        * center point \n",
    "        * frame scale\n",
    "\n",
    "## Source structure\n",
    "    * main - opens run_parameters file - passes to module function\n",
    "    * selection and tracking module\n",
    "    * starting plain complex\n",
    "    * equations module\n",
    "    * iteration module\n",
    "    * matrix to image module\n",
    "***\n",
    "[PIL image](https://pillow.readthedocs.io/en/5.1.x/reference/Image.html#the-image-class) <br>\n",
    "****\n",
    "[GitHub scalygraphic](https://github.com/dlanier/scalygraphic/) <br>\n",
    "### Background Code:\n",
    "[Add: random plane on domain](https://github.com/dlanier/scalygraphic/blob/master/scalygraphic/zplain.py) <br>\n",
    "\n",
    "#### Import & Expand *functions_demo.py*\n",
    "[FMF functions_demo](https://github.com/dlanier/FlyingMachineFractal/blob/master/pyreimpic/functions_demo_01.py) <br>\n",
    "#### Import & Trim itergators.py\n",
    "[FMF itergators](https://github.com/dlanier/FlyingMachineFractal/blob/master/src/itergataters.py) <br>\n",
    "#### Rewrite HSV coloring\n",
    "[FMF graphic_utility.py](https://github.com/dlanier/FlyingMachineFractal/blob/master/src/graphic_utility.py) <br>\n",
    "[FMF numcolorpy.py](https://github.com/dlanier/FlyingMachineFractal/blob/master/src/numcolorpy.py) <br>\n",
    "#### Reslove plain functions\n",
    "[FMF z_plane.py](https://github.com/dlanier/FlyingMachineFractal/blob/master/src/z_plane.py) <br>\n",
    "****\n",
    "    \n",
    "### Inception: Random Selection, Tracking and Generation - called from *main()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clickety Clack:\n",
    "## production_parameters: *output_dir_name, image_sizes_dict, number_of_sets*\n",
    "### get a random eq & p with a random domain\n",
    "#### check uniquness\n",
    "### get a random color map\n",
    "## Iterate: run, write, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    ../src/im_scale_products.py\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import hashlib\n",
    "import inspect\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "sys.path.insert(0, '../src/')\n",
    "\n",
    "import zplain as zp\n",
    "import eq_iter\n",
    "import deg_0_ddeq\n",
    "import numcolorpy as ncp\n",
    "\n",
    "\"\"\"     Constants (lookups):\n",
    "\n",
    "        EQUS_DICT is an enumerated dictionary of the functions in module deg_0_ddeq\n",
    "        EQUS_DICT_NAMED_IDX is a dictionary - name: number index of EQUS_DICT \n",
    "\"\"\"\n",
    "EQUS_DICT = {k: v for k, v in enumerate(inspect.getmembers(deg_0_ddeq, inspect.isfunction))}\n",
    "EQUS_DICT_NAMED_IDX = {v[0]: k for k, v in EQUS_DICT.items()}\n",
    "\n",
    "def get_rand_eq_p_set():\n",
    "    \"\"\" get a random equation and parameter set from the deg_0_ddeq module\n",
    "    (No Args:)\n",
    "    Returns:\n",
    "        tuple:      (function_name, function_handle, parameter_set)\n",
    "    \"\"\"\n",
    "    n = np.random.randint(0,len(EQUS_DICT),1)\n",
    "    fcn_name, fcn = EQUS_DICT[n[0]]\n",
    "    p = fcn(0.0, None)\n",
    "\n",
    "    return (fcn_name, fcn, p)\n",
    "\n",
    "def get_eq_by_name(fcn_name):\n",
    "    \"\"\" Usage: function_handle = get_eq_by_name(fcn_name)\n",
    "    Args:\n",
    "        name of a function in deg_0_ddeq\n",
    "    \"\"\"\n",
    "    if fcn_name in EQUS_DICT_NAMED_IDX:\n",
    "        return EQUS_DICT[EQUS_DICT_NAMED_IDX[fcn_name]][1]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_random_domain(bounds_dict=None):\n",
    "    \"\"\" Usage: \n",
    "    domain_dict = get_random_domain(h, w, bounds_dict)\n",
    "    \n",
    "    Args:\n",
    "        bounds_dict:    min - max limits for keys eg.\n",
    "                            CP_magnitude_limits = {'min': 0, 'max': 7}\n",
    "                            ZM_limits           = {'min': np.finfo(float).eps, 'max': 2}\n",
    "                            theta_limits        = {'min': 0, 'max':2 * np.pi}\n",
    "                        \n",
    "    Returns:\n",
    "        domain_dict:    with keys:\n",
    "                            center_point\n",
    "                            zoom\n",
    "                            theta\n",
    "    \"\"\"\n",
    "    domain_dict = {}\n",
    "    if bounds_dict is None:\n",
    "        CP_magnitude_limits =   {'min': 0, 'max': 2}\n",
    "        ZM_limits =             {'min': np.finfo(float).eps, 'max': 1}\n",
    "        theta_limits =          {'min': 0, 'max':2 * np.pi}\n",
    "    else:\n",
    "        CP_magnitude_limits =   bounds_dict['CP_magnitude_limits']\n",
    "        ZM_limits =             bounds_dict['ZM_limits']\n",
    "        theta_limits =          bounds_dict['theta_limits']\n",
    "\n",
    "    r = np.random.uniform(low=0.0, high=2*np.pi) * 0.0+1.0j\n",
    "    m = np.random.uniform(low=CP_magnitude_limits['min'], high=CP_magnitude_limits['max'])\n",
    "    domain_dict['center_point'] = m*np.exp(r)\n",
    "    domain_dict['zoom'] = np.random.uniform(low=ZM_limits['min'], high=ZM_limits['max'])\n",
    "    domain_dict['theta'] = np.random.uniform(low=theta_limits['min'], high=theta_limits['max'])\n",
    "    \n",
    "    return domain_dict\n",
    "\n",
    "def sha256sum(s):\n",
    "    \"\"\" Usage:  hash_key = sha256sum(input_str)\n",
    "    \"\"\"\n",
    "    h  = hashlib.sha256()\n",
    "    h.update(bytes(s, 'ascii'))\n",
    "    \n",
    "    return h.hexdigest()\n",
    "\n",
    "def hash_parameters(domain_dict, fcn_name, p):\n",
    "    \"\"\" Usage: hash_key = hash_parameters(domain_dict, fcn_name, p)\n",
    "    \"\"\"\n",
    "    N_DEC = 15\n",
    "    f = zp.get_frame_from_dict(domain_dict)\n",
    "    s = zp.complex_frame_dict_to_string(f, N_DEC) + '\\n' + fcn_name\n",
    "    if isinstance(p, list):\n",
    "        p_str = ''\n",
    "        for p_n in p:\n",
    "            p_str += zp.complex_to_string(p_n, N_DEC)\n",
    "    else:\n",
    "        p_str = zp.complex_to_string(p, N_DEC)\n",
    "    \n",
    "    s += p_str\n",
    "    \n",
    "    return sha256sum(s)\n",
    "\n",
    "def get_im(ET, Z, Z0, domain_dict):\n",
    "    \"\"\" Usage: I = get_im(ET, Z, Z0)\n",
    "    \"\"\"\n",
    "    Zd, Zr, ETn = ncp.etg_norm(Z0, Z, ET)\n",
    "\n",
    "    A = np.zeros((domain_dict['n_rows'], domain_dict['n_cols'],3))\n",
    "    A[:,:,0] += ETn     # Hue\n",
    "    A[:,:,1] += Zr      # Saturation\n",
    "    A[:,:,2] += Zd      # Value\n",
    "    I = PIL.Image.fromarray(np.uint8(A * 255), 'HSV').convert('RGB')\n",
    "    \n",
    "    return I\n",
    "\n",
    "def get_gray_im(ET, Z, Z0, et_gray=False):\n",
    "    \"\"\" Usage: I = get_im(ET, Z, Z0)\n",
    "    \"\"\"\n",
    "    Zd, Zr, ETn = ncp.etg_norm(Z0, Z, ET)\n",
    "    \n",
    "    if et_gray:\n",
    "        I = PIL.Image.fromarray(np.uint8(ETn * 255), 'L')\n",
    "    else:\n",
    "        I = PIL.Image.fromarray(np.uint8(Zd * 255), 'L')\n",
    "    \n",
    "    return I\n",
    "\n",
    "def now_name(prefi_str=None, suffi_str=None):\n",
    "    \"\"\" get a human readable time stamp name \"\"\"\n",
    "    t0 = time.time()\n",
    "    t_dec = t0 - np.floor(t0)\n",
    "    ahora_nombre = time.strftime(\"%a_%d_%b_%Y_%H_%M_%S\", time.localtime()) \n",
    "    if prefi_str is None: prefi_str = ''\n",
    "    if suffi_str is None: suffi_str = ''\n",
    "        \n",
    "    return prefi_str + '_' + ahora_nombre + suffi_str\n",
    "\n",
    "\n",
    "def write_n_image_sets(n_2_do, iteration_dict, small_scale, large_scale, output_directory, hash_list=[]):\n",
    "    \"\"\"Usage:\n",
    "                hash_list = write_n_image_sets( n_2_do, \n",
    "                                                iteration_dict, \n",
    "                                                small_scale, \n",
    "                                                large_scale, \n",
    "                                                output_directory, \n",
    "                                                hash_list )\n",
    "    \"\"\"\n",
    "    if os.path.isdir(output_directory) == False:\n",
    "        os.makedirs(output_directory)\n",
    "                \n",
    "    print(now_name('Write %i image pairs to \\n%s\\nStart '%(n_2_do, output_directory)))\n",
    "    \n",
    "    if len(hash_list) > 0:\n",
    "        print('checking duplicates using input hash_list size = %i'%(len(hash_list)))\n",
    "    else:\n",
    "        print('new hash list started')\n",
    "\n",
    "    with TemporaryDirectory() as test_temporary_dir:\n",
    "\n",
    "        for k_do in range(n_2_do):\n",
    "            fcn_name, eq, p = get_rand_eq_p_set()\n",
    "            domain_dict = get_random_domain()\n",
    "\n",
    "            domain_dict['it_max'] = iteration_dict['it_max']\n",
    "            domain_dict['max_d'] = iteration_dict['scale_dist'] / domain_dict['zoom']\n",
    "\n",
    "            hash_idx = hash_parameters(domain_dict, fcn_name, p)\n",
    "            if hash_idx in hash_list:\n",
    "                pass\n",
    "            else:\n",
    "                hash_list.append(hash_idx)\n",
    "                domain_dict['n_rows'] = small_scale[0]\n",
    "                domain_dict['n_cols'] = small_scale[1]\n",
    "                domain_dict['dir_path'] = test_temporary_dir\n",
    "\n",
    "                list_tuple = [(eq, (p))]\n",
    "\n",
    "                t0 = time.time()\n",
    "                ET, Z, Z0 = eq_iter.get_primitives(list_tuple, domain_dict)\n",
    "                I = get_im(ET, Z, Z0, domain_dict)\n",
    "                file_name = os.path.join(output_directory, hash_idx + '_' + 'small.jpg')\n",
    "                I.save(file_name)\n",
    "\n",
    "                domain_dict['n_rows'] = large_scale[0]\n",
    "                domain_dict['n_cols'] = large_scale[1]\n",
    "\n",
    "                ET, Z, Z0 = eq_iter.get_primitives(list_tuple, domain_dict)\n",
    "                I = get_im(ET, Z, Z0, domain_dict)\n",
    "                file_name = os.path.join(output_directory, hash_idx + '_' + 'large.jpg')\n",
    "                I.save(file_name)\n",
    "                print('\\n%3i of %3i) %s\\t\\t'%(k_do+1, n_2_do, fcn_name), \n",
    "                      '%0.3f seconds (large & small image written)\\n'%(time.time() - t0), \n",
    "                      hash_idx)\n",
    "                \n",
    "    print('\\n', now_name('%i pairs written,\\nFinished '%(k_do + 1)))\n",
    "    \n",
    "    return hash_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demos:\n",
    "\n",
    "****\n",
    "## get a random function and parameter set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t RoyalZ\n",
      "0j\n",
      "inf\n",
      "(1+1j)\n",
      "(0.3279228087512498-0.8529740622329691j)\n",
      "\n",
      "\t Nautuliz\n",
      "0j\n",
      "inf\n",
      "(1+1j)\n",
      "(0.7890985453389898-0.18370730130703805j)\n",
      "\n",
      "\t ElGato\n",
      "0j\n",
      "inf\n",
      "(1+1j)\n",
      "(1.3861649239416862-0.16582757079924598j)\n",
      "\n",
      "\t de_Okeeffe\n",
      "0j\n",
      "(-6.019728155339806+0.057856310679611646j)\n",
      "(1+1j)\n",
      "(-0.2221851582698301+0.2551022026406169j)\n",
      "\n",
      "\t IslaLace\n",
      "0j\n",
      "inf\n",
      "(1+1j)\n",
      "(1.4559758142625245-1.102089495118849j)\n"
     ]
    }
   ],
   "source": [
    "n_trys = 5\n",
    "\n",
    "for k in range(n_trys):\n",
    "    fcn_name, eq, p = get_rand_eq_p_set()\n",
    "    \n",
    "    print('\\n\\t', fcn_name)\n",
    "    try:\n",
    "        Z = 0.0+0.0j\n",
    "        print(Z)\n",
    "        print(eq(Z,p))\n",
    "        Z = 1.0+1.0j\n",
    "        print(Z)\n",
    "        print(eq(Z,p))\n",
    "    except:\n",
    "        print('Crash crash ')\n",
    "        break\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get a random complex domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upper_left:1.7416-3.2670j\ttop_center:-0.9721-1.5438j\tupper_right:-3.6857+0.1794j\n",
      "left_center:3.4648-0.5534j\tcenter_point:1.5023+2.3397j\tright_center:-1.9625+2.8931j\n",
      "bottom_left:5.1881+2.1603j\tbottom_center:2.4744+3.8835j\tbottom_right:-0.2393+5.6068j\n",
      " \n",
      "                                 (from dictionary)\n",
      "                            center_point: 0.751+1.170j\n",
      "                                    zoom: 0\n",
      "                                   theta: 2\n"
     ]
    }
   ],
   "source": [
    "N_DEC=4\n",
    "\n",
    "domain_dict = get_random_domain()\n",
    "f = zp.get_frame_from_dict(domain_dict)\n",
    "s = zp.complex_frame_dict_to_string(f, N_DEC)\n",
    "print(s,'\\n%50s'%('(from dictionary)'))\n",
    "for k, v in domain_dict.items():\n",
    "    if isinstance(v, complex):\n",
    "        v_str = zp.complex_to_string(v)\n",
    "    else:\n",
    "        v_str = '%i'%(v)\n",
    "        \n",
    "    print('%40s: %s'%(k, v_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *hash_parameters( )* - function, parameters & domain - (reject duplicate parameters)\n",
    "    Option: hashed dict > json file to allow reproduction of an exact data-set with different scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce0914821e2eb728f59a486da04d85cb4e7bd14461d64fea2736a6977395fbe6\n"
     ]
    }
   ],
   "source": [
    "fcn_name, eq, p = get_rand_eq_p_set()\n",
    "domain_dict = get_random_domain()\n",
    "\n",
    "hash_key = hash_parameters(domain_dict, fcn_name, p)\n",
    "print(hash_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce many pair of scaled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write 2 image pairs to \n",
      "../../ImagesSunday\n",
      "Start _Sun_22_Sep_2019_16_35_40\n",
      "checking duplicates using input hash_list size = 2\n",
      "\n",
      "  1 of   2) RoyalZ\t\t 12.046 seconds (large & small image written)\n",
      " 4ec440f62d94fdd06d4dd22e6714de388a6c5c9f8130ecdb87f0b4b391d64c22\n",
      "\n",
      "  2 of   2) RoyalZ\t\t 20.156 seconds (large & small image written)\n",
      " 7937e44ed77c804619683fea7a499314ebbbda61787cfab44d919dd37e5ac8d5\n",
      "\n",
      " 2 pairs written,\n",
      "Finished _Sun_22_Sep_2019_16_36_12\n",
      "\n",
      "total cell time: 32.21 seconds\n"
     ]
    }
   ],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "n_2_do = 2\n",
    "iteration_dict = {'it_max': 64, 'scale_dist': 10}\n",
    "small_scale = [128, 128]\n",
    "large_scale = [255, 255]\n",
    "\n",
    "output_directory = '../../ImagesSunday'\n",
    "if os.path.isdir(output_directory) == False:\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "hash_list = write_n_image_sets(n_2_do, iteration_dict, small_scale, large_scale, output_directory, hash_list)\n",
    "\n",
    "tt = time.time() - cell_start_time\n",
    "print('\\ntotal cell time: %0.2f seconds'%(tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## file nameing ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_da = now_name(prefi_str=fcn_name, suffi_str='.jpg')\n",
    "print(do_da)\n",
    "d0_dat = hashy_list[0] + '.jpg'\n",
    "print(d0_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coloring logic\n",
    "    * HSV model - choose three result components\n",
    "        * Hue        (red to red) (0, 1) * 255          == visible spectrum colors\n",
    "        * Saturation (gray to solid color) (0, 1) * 255 == color intensity\n",
    "        * Value      (black to white) (0, 1) * 255      == brightness\n",
    "    * RGB conversion from HSV\n",
    "        * portable for multiple file formats\n",
    "        * norm for train - validate - test\n",
    "    * Escape-time algorithm produces\n",
    "        * Escape Time (integer matrix)\n",
    "        * Final Vector (Z - Z0)\n",
    "            * distance (float matrix)\n",
    "            * rotation (float matrix)\n",
    "****\n",
    "### Coloring component normalization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_component_color_range(Z0, Z, ET):\n",
    "    # Examine color ranges - for HSV - RGB conversion \n",
    "    Zd_t, Zr_t, ETn_t = ncp.etg_norm(Z0, Z, ET)\n",
    "    print('\\nZd_t', np.max(Zd_t), np.min(Zd_t))\n",
    "    print('Zr_t', np.max(Zr_t), np.min(Zr_t))\n",
    "    print('ETn_t', np.max(ETn_t), np.min(ETn_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
