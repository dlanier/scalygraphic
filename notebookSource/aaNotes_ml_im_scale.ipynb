{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Scaling with Machine Learning\n",
    "## Inputs:\n",
    "    1) Number of image pairs\n",
    "    2) dictionary of {size_label_A: [pixels_high, pixels_wide], \n",
    "                      size_label_B: [pixels_high, pixels_wide]}\n",
    "    3) run directory\n",
    "    4) output directory\n",
    "    5) existing sets parameters.json (None for first run)\n",
    "***\n",
    "## Parameters to generate a set of images for train-test-validate\n",
    "    * Over all parameters\n",
    "        * number of image sets\n",
    "        * sizes dict {name1: [h, w], name2: [h, w],...}\n",
    "        * run-limits {escape_boundry: diagonal_multiplier, max_iterations: int}\n",
    "        * coloring scheme - perhaps a function\n",
    "        * output file format\n",
    "        * ouput file naming format\n",
    "    * File system\n",
    "        * output directory {train: path, test: path, validate: path}\n",
    "        * run-log location\n",
    "    * Stocastic Choices:\n",
    "        * hashed dictionary - to reject duplicate images\n",
    "        * equation\n",
    "            * parameters\n",
    "        * rotation \n",
    "        * center point \n",
    "        * frame scale\n",
    "\n",
    "## Source structure\n",
    "    * main - opens run_parameters file - passes to module function\n",
    "    * selection and tracking module\n",
    "    * starting plain complex\n",
    "    * equations module\n",
    "    * iteration module\n",
    "    * matrix to image module\n",
    "***\n",
    "[PIL image](https://pillow.readthedocs.io/en/5.1.x/reference/Image.html#the-image-class) <br>\n",
    "****\n",
    "[GitHub scalygraphic](https://github.com/dlanier/scalygraphic/) <br>\n",
    "### Background Code:\n",
    "[Add: random plane on domain](https://github.com/dlanier/scalygraphic/blob/master/scalygraphic/zplain.py) <br>\n",
    "\n",
    "#### Import & Expand *functions_demo.py*\n",
    "[FMF functions_demo](https://github.com/dlanier/FlyingMachineFractal/blob/master/pyreimpic/functions_demo_01.py) <br>\n",
    "#### Import & Trim itergators.py\n",
    "[FMF itergators](https://github.com/dlanier/FlyingMachineFractal/blob/master/src/itergataters.py) <br>\n",
    "#### Rewrite HSV coloring\n",
    "[FMF graphic_utility.py](https://github.com/dlanier/FlyingMachineFractal/blob/master/src/graphic_utility.py) <br>\n",
    "[FMF numcolorpy.py](https://github.com/dlanier/FlyingMachineFractal/blob/master/src/numcolorpy.py) <br>\n",
    "#### Reslove plain functions\n",
    "[FMF z_plane.py](https://github.com/dlanier/FlyingMachineFractal/blob/master/src/z_plane.py) <br>\n",
    "****\n",
    "    \n",
    "### Inception: Random Selection, Tracking and Generation - called from *main()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.insert(0, '../src/')\n",
    "sys.path.insert(0, 'scalygraphic/src/')\n",
    "\n",
    "# import zplain as zp\n",
    "# import eq_iter\n",
    "# import deg_0_ddeq\n",
    "# import numcolorpy as ncp\n",
    "from im_scale_products import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clickety Clack:\n",
    "## production_parameters: *output_dir_name, image_sizes_dict, number_of_sets*\n",
    "### get a random eq & p with a random domain\n",
    "#### check uniquness\n",
    "### get a random color map\n",
    "## Iterate: run, write, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile ../src/im_scale_products.py\n",
    "\"\"\"\n",
    "Collection of functions to run image production for machine learning applications\n",
    "\n",
    "See the Makefile and ../data/run_files/ for usage examples\n",
    "\"\"\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import hashlib\n",
    "import inspect\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "# development running from clone-mount directory or (this) src dir\n",
    "sys.path.insert(0, '../src/')\n",
    "sys.path.insert(0, 'scalygraphic/src/')\n",
    "\n",
    "import zplain as zp\n",
    "import eq_iter\n",
    "import deg_0_ddeq\n",
    "# import numcolorpy as ncp\n",
    "import impute_color as ncp\n",
    "\n",
    "\"\"\"     Constants (lookups):\n",
    "\n",
    "        EQUS_DICT is an enumerated dictionary of the functions in module deg_0_ddeq\n",
    "        EQUS_DICT_NAMED_IDX is a dictionary index {name: enumeration_number} of EQUS_DICT\n",
    "\"\"\"\n",
    "EQUS_DICT = {k: v for k, v in enumerate(inspect.getmembers(deg_0_ddeq, inspect.isfunction))}\n",
    "EQUS_DICT_NAMED_IDX = {v[0]: k for k, v in EQUS_DICT.items()}\n",
    "\n",
    "def get_rand_eq_p_set():\n",
    "    \"\"\" get a random equation and parameter set from the deg_0_ddeq module\n",
    "    (No Args:)\n",
    "    \n",
    "    Returns:\n",
    "        tuple:      (function_name, function_handle, parameter_set)\n",
    "    \"\"\"\n",
    "    n = np.random.randint(0,len(EQUS_DICT),1)\n",
    "    fcn_name, fcn = EQUS_DICT[n[0]]\n",
    "    p = fcn(0.0, None)\n",
    "\n",
    "    return (fcn_name, fcn, p)\n",
    "\n",
    "def get_eq_by_name(fcn_name):\n",
    "    \"\"\" get the function handle from the function name\n",
    "    \n",
    "    Args:\n",
    "        fcn_name:   name of a function in deg_0_ddeq\n",
    "        \n",
    "    Returns:\n",
    "        fcn_handle: callable function Z = fcn_name(Z, p, (Z0), (ET))\n",
    "        \n",
    "    \"\"\"\n",
    "    if fcn_name in EQUS_DICT_NAMED_IDX:\n",
    "        return EQUS_DICT[EQUS_DICT_NAMED_IDX[fcn_name]][1]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def get_random_domain(bounds_dict=None):\n",
    "    \"\"\" Usage: \n",
    "    domain_dict = get_random_domain(h, w, bounds_dict)\n",
    "    \n",
    "    Args:\n",
    "        bounds_dict:    min - max limits for keys eg.\n",
    "                            CP_magnitude_limits = {'min': 0, 'max': 7}\n",
    "                            ZM_limits           = {'min': np.finfo(float).eps, 'max': 2}\n",
    "                            theta_limits        = {'min': 0, 'max':2 * np.pi}\n",
    "                        \n",
    "    Returns:\n",
    "        domain_dict:    with keys:\n",
    "                            center_point\n",
    "                            zoom\n",
    "                            theta\n",
    "    \"\"\"\n",
    "    domain_dict = {}\n",
    "    if bounds_dict is None:\n",
    "        CP_magnitude_limits =   {'min': 0, 'max': 2}\n",
    "        ZM_limits =             {'min': np.finfo(float).eps, 'max': 1}\n",
    "        theta_limits =          {'min': 0, 'max':2 * np.pi}\n",
    "    else:\n",
    "        CP_magnitude_limits =   bounds_dict['CP_magnitude_limits']\n",
    "        ZM_limits =             bounds_dict['ZM_limits']\n",
    "        theta_limits =          bounds_dict['theta_limits']\n",
    "\n",
    "    r = np.random.uniform(low=0.0, high=2*np.pi) * 0.0+1.0j\n",
    "    m = np.random.uniform(low=CP_magnitude_limits['min'], high=CP_magnitude_limits['max'])\n",
    "    domain_dict['center_point'] = m*np.exp(r)\n",
    "    domain_dict['zoom'] = np.random.uniform(low=ZM_limits['min'], high=ZM_limits['max'])\n",
    "    domain_dict['theta'] = np.random.uniform(low=theta_limits['min'], high=theta_limits['max'])\n",
    "    \n",
    "    return domain_dict\n",
    "\n",
    "def sha256sum(s):\n",
    "    \"\"\" convert a string to a 256 bit hash key as a string\n",
    "    \n",
    "    Args:\n",
    "        s:          string\n",
    "        \n",
    "    Returns:\n",
    "        hash_key:   256 bit hex as string\n",
    "\n",
    "    \"\"\"\n",
    "    h  = hashlib.sha256()\n",
    "    h.update(bytes(s, 'ascii'))\n",
    "    \n",
    "    return h.hexdigest()\n",
    "\n",
    "def hash_parameters(domain_dict, fcn_name, p):\n",
    "    \"\"\" get a hash value of equation production parameters to compare uniqueness\n",
    "    \n",
    "    Args:\n",
    "        domain_dict:    parameters defining numerical domain on the complex plain\n",
    "        fcn_name:       equation function name\n",
    "        p:              equation parameter inputs\n",
    "        \n",
    "    Returns:\n",
    "        hash_key:   256 bit hex as string\n",
    "    \"\"\"\n",
    "    N_DEC = 15\n",
    "    f = zp.get_frame_from_dict(domain_dict)\n",
    "    s = zp.complex_frame_dict_to_string(f, N_DEC) + '\\n' + fcn_name\n",
    "    if isinstance(p, list):\n",
    "        p_str = ''\n",
    "        for p_n in p:\n",
    "            p_str += zp.complex_to_string(p_n, N_DEC)\n",
    "    else:\n",
    "        p_str = zp.complex_to_string(p, N_DEC)\n",
    "    \n",
    "    s += p_str\n",
    "    \n",
    "    return sha256sum(s)\n",
    "\n",
    "def get_im(ET, Z, Z0):\n",
    "    \"\"\" get a color image from  the products of the escape-time-algorithm Using HSV - RGB model:\n",
    "    ETn         normalized escape time matrix           Hue\n",
    "    Zr          normalized rotation of |Z - Z0|         Saturation\n",
    "    Zd          normalized magnitude of |Z - Z0|        Value\n",
    "    \n",
    "    Args:\n",
    "        ET:     (Integer) matrix of the Escape Times    \n",
    "        Z:      (complex) matrix of the final vectors   \n",
    "        Z0:     (complex) matrix of the starting plane\n",
    "        \n",
    "    Returns:\n",
    "        I:      RGB PIL image\n",
    "\n",
    "    \"\"\"\n",
    "    n_rows = np.shape(ET)[0]\n",
    "    n_cols = np.shape(ET)[1]\n",
    "    Zd, Zr, ETn = ncp.etg_norm(Z0, Z, ET)\n",
    "\n",
    "    A = np.zeros((n_rows, n_cols, 3))\n",
    "    A[:,:,0] += ETn     # Hue\n",
    "    A[:,:,1] += Zr      # Saturation\n",
    "    A[:,:,2] += Zd      # Value\n",
    "    I = PIL.Image.fromarray(np.uint8(A * 255), 'HSV').convert('RGB')\n",
    "    \n",
    "    return I\n",
    "\n",
    "def get_gray_im(ET, Z, Z0):\n",
    "    \"\"\" get a gray-scale image from the products of the escape-time-algorithm\n",
    "    \n",
    "    Args:\n",
    "        ET:     (Integer) matrix of the Escape Times\n",
    "        Z:      (complex) matrix of the final vectors\n",
    "        Z0:     (complex) matrix of the starting plane\n",
    "        \n",
    "    Returns:\n",
    "        I:      grayscale PIL image\n",
    "    \"\"\"\n",
    "    return get_im(Z0, Z, ET).convert('L')\n",
    "\n",
    "def now_name(prefi_str=None, suffi_str=None):\n",
    "    \"\"\" get a human readable time stamp name \n",
    "    \n",
    "    Args:\n",
    "        prefi_str:\n",
    "        suffi_str:\n",
    "        \n",
    "    Returns:\n",
    "        now_string: prefi_str + '_' + formatted_time_string + suffi_str\n",
    "                    eg.  myfilebasename_Mon_23_Sep_2019_06_06_54.tiff\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    t_dec = t0 - np.floor(t0)\n",
    "    ahora_nombre = time.strftime(\"%a_%d_%b_%Y_%H_%M_%S\", time.localtime()) \n",
    "    if prefi_str is None: prefi_str = ''\n",
    "    if suffi_str is None: suffi_str = ''\n",
    "        \n",
    "    return prefi_str + '_' + ahora_nombre + suffi_str\n",
    "\n",
    "\n",
    "def write_n_image_sets(n_2_do, iteration_dict, small_scale, large_scale, output_dir, hash_list=[]):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        n_2_do:         number of pairs of images\n",
    "        iteration_dict: {'it_max': 64, 'scale_dist': 10} escape-time-algorithm iteration limits\n",
    "        small_scale:    [h, w] for smaller copy of image\n",
    "        large_scale:    [h, w] for larger copy of image\n",
    "        output_dir:     directory will be written if DNE\n",
    "        hash_list       empty list []  OR  list returned by this function - to avoid duplicates\n",
    "        \n",
    "    Returns:\n",
    "        hash_list:      list of parameter encodings to insure uniqueness \n",
    "                        if producing large dataset over multiple sessions or locations\n",
    "                        \n",
    "    Writes n_2_do image pairs like:\n",
    "                        asdregshaaldfkaproiapw_small.jpg\n",
    "                        asdregshaaldfkaproiapw_large.jpg\n",
    "    \"\"\"\n",
    "    if os.path.isdir(output_dir) == False:\n",
    "        os.makedirs(output_dir)\n",
    "                \n",
    "    print(now_name('Write %i image pairs to \\n%s\\nStart '%(n_2_do, output_dir)))\n",
    "    \n",
    "    if len(hash_list) > 0:\n",
    "        print('checking duplicates using input hash_list size = %i'%(len(hash_list)))\n",
    "    else:\n",
    "        print('new hash list started')\n",
    "\n",
    "    with TemporaryDirectory() as test_temporary_dir:\n",
    "\n",
    "        for k_do in range(n_2_do):\n",
    "            fcn_name, eq, p = get_rand_eq_p_set()\n",
    "            domain_dict = get_random_domain()\n",
    "\n",
    "            domain_dict['it_max'] = iteration_dict['it_max']\n",
    "            domain_dict['max_d'] = iteration_dict['scale_dist'] / domain_dict['zoom']\n",
    "\n",
    "            hash_idx = hash_parameters(domain_dict, fcn_name, p)\n",
    "            if hash_idx in hash_list:\n",
    "                pass\n",
    "            else:\n",
    "                hash_list.append(hash_idx)\n",
    "                domain_dict['n_rows'] = small_scale[0]\n",
    "                domain_dict['n_cols'] = small_scale[1]\n",
    "                domain_dict['dir_path'] = test_temporary_dir\n",
    "\n",
    "                list_tuple = [(eq, (p))]\n",
    "\n",
    "                t0 = time.time()\n",
    "                ET, Z, Z0 = eq_iter.get_primitives(list_tuple, domain_dict)\n",
    "                if GRAYSCALE == True:\n",
    "                    I = get_gray_im(ET, Z, Z0)\n",
    "                else:\n",
    "                    I = get_im(ET, Z, Z0)\n",
    "\n",
    "                file_name = os.path.join(output_dir, hash_idx + '_' + 'small.jpg')\n",
    "                I.save(file_name)\n",
    "\n",
    "                domain_dict['n_rows'] = large_scale[0]\n",
    "                domain_dict['n_cols'] = large_scale[1]\n",
    "\n",
    "                ET, Z, Z0 = eq_iter.get_primitives(list_tuple, domain_dict)\n",
    "                if GRAYSCALE == True:\n",
    "                    I = get_gray_im(ET, Z, Z0)\n",
    "                else:\n",
    "                    I = get_im(ET, Z, Z0)\n",
    "\n",
    "                file_name = os.path.join(output_dir, hash_idx + '_' + 'large.jpg')\n",
    "                I.save(file_name)\n",
    "                print('\\n%3i of %3i) %s\\t\\t'%(k_do+1, n_2_do, fcn_name), \n",
    "                      '%0.3f seconds (large & small image written)\\n'%(time.time() - t0), \n",
    "                      hash_idx)\n",
    "                \n",
    "    print('\\n', now_name('%i pairs written,\\nFinished '%(k_do + 1)))\n",
    "    \n",
    "    return hash_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demos:\n",
    "\n",
    "****\n",
    "## get a random function and parameter set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trys = 5\n",
    "\n",
    "for k in range(n_trys):\n",
    "    fcn_name, eq, p = get_rand_eq_p_set()\n",
    "    \n",
    "    print('\\n\\t', fcn_name)\n",
    "    try:\n",
    "        Z = 0.0+0.0j\n",
    "        print(Z)\n",
    "        print(eq(Z,p))\n",
    "        Z = 1.0+1.0j\n",
    "        print(Z)\n",
    "        print(eq(Z,p))\n",
    "    except:\n",
    "        print('Crash crash ')\n",
    "        break\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get a random complex domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_DEC=4\n",
    "\n",
    "domain_dict = get_random_domain()\n",
    "f = zp.get_frame_from_dict(domain_dict)\n",
    "s = zp.complex_frame_dict_to_string(f, N_DEC)\n",
    "print(s,'\\n%50s'%('(from dictionary)'))\n",
    "for k, v in domain_dict.items():\n",
    "    if isinstance(v, complex):\n",
    "        v_str = zp.complex_to_string(v)\n",
    "    else:\n",
    "        v_str = '%i'%(v)\n",
    "        \n",
    "    print('%40s: %s'%(k, v_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *hash_parameters( )* - function, parameters & domain - (reject duplicate parameters)\n",
    "    Option: hashed dict > json file to allow reproduction of an exact data-set with different scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_name, eq, p = get_rand_eq_p_set()\n",
    "domain_dict = get_random_domain()\n",
    "\n",
    "hash_key = hash_parameters(domain_dict, fcn_name, p)\n",
    "print(hash_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce many pair of scaled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#             or use saved list\n",
    "hash_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "n_2_do = 2\n",
    "iteration_dict = {'it_max': 64, 'scale_dist': 10}\n",
    "small_scale = [128, 128]\n",
    "large_scale = [255, 255]\n",
    "\n",
    "output_directory = '../../ImagesSunday'\n",
    "if os.path.isdir(output_directory) == False:\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "hash_list = write_n_image_sets(n_2_do, iteration_dict, small_scale, large_scale, output_directory, hash_list)\n",
    "\n",
    "tt = time.time() - cell_start_time\n",
    "print('\\ntotal cell time: %0.2f seconds'%(tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## file nameing ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_da = now_name(prefi_str=fcn_name, suffi_str='.jpg')\n",
    "print(do_da)\n",
    "d0_dat = hash_list[0] + '.jpg'\n",
    "print(d0_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coloring logic\n",
    "    * HSV model - choose three result components\n",
    "        * Hue        (red to red) (0, 1) * 255          == visible spectrum colors\n",
    "        * Saturation (gray to solid color) (0, 1) * 255 == color intensity\n",
    "        * Value      (black to white) (0, 1) * 255      == brightness\n",
    "    * RGB conversion from HSV\n",
    "        * portable for multiple file formats\n",
    "        * norm for train - validate - test\n",
    "    * Escape-time algorithm produces\n",
    "        * Escape Time (integer matrix)\n",
    "        * Final Vector (Z - Z0)\n",
    "            * distance (float matrix)\n",
    "            * rotation (float matrix)\n",
    "****\n",
    "### Coloring component normalization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_component_color_range(Z0, Z, ET):\n",
    "    # Examine color ranges - for HSV - RGB conversion \n",
    "    Zd_t, Zr_t, ETn_t = ncp.etg_norm(Z0, Z, ET)\n",
    "    print('\\nZd_t', np.max(Zd_t), np.min(Zd_t))\n",
    "    print('Zr_t', np.max(Zr_t), np.min(Zr_t))\n",
    "    print('ETn_t', np.max(ETn_t), np.min(ETn_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development legacy - cell below replaced by function:\n",
    "```python\n",
    "# Use hash_list for multi-session calling to avoid (improbable) duplicate parameter sets\n",
    "hash_list = write_n_image_sets(n_2_do, iteration_dict, small_scale, large_scale, output_directory, hash_list)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashy_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "n_2_do = 3\n",
    "\n",
    "test_temporary_dir = '../../test_temporary_dir'\n",
    "if os.path.isdir(test_temporary_dir) == False:\n",
    "    os.makedirs(test_temporary_dir)\n",
    "\n",
    "DISPLAY_IN_NOTEBOOK = True\n",
    "GRAYSCALE = True\n",
    "\n",
    "small_scale = [128, 128]\n",
    "large_scale = [255, 255]\n",
    "output_directory = '../../ImagesFriday'\n",
    "if os.path.isdir(output_directory) == False:\n",
    "    os.makedirs(output_directory)\n",
    "    \n",
    "\n",
    "for k_do in range(n_2_do):\n",
    "    fcn_name, eq, p = get_rand_eq_p_set()\n",
    "    print('\\n%3i) %s'%(k_do+1, fcn_name))\n",
    "    domain_dict = get_random_domain()\n",
    "\n",
    "    domain_dict['it_max'] = 64\n",
    "    domain_dict['max_d'] = 10 / domain_dict['zoom']\n",
    "\n",
    "    hash_idx = hash_parameters(domain_dict, fcn_name, p)\n",
    "    if hash_idx in hashy_list:\n",
    "        print('\\n\\n\\t\\tImpossible! But! Skipping:\\n%s\\n'%(hash_idx))\n",
    "    else:\n",
    "        hashy_list.append(hash_idx)\n",
    "        print(hash_idx + '\\n')\n",
    "        domain_dict['n_rows'] = small_scale[0]\n",
    "        domain_dict['n_cols'] = small_scale[1]\n",
    "\n",
    "        domain_dict['dir_path'] = test_temporary_dir\n",
    "\n",
    "        list_tuple = [(eq, (p))]\n",
    "\n",
    "        t0 = time.time()\n",
    "        ET, Z, Z0 = eq_iter.get_primitives(list_tuple, domain_dict)\n",
    "        if GRAYSCALE == True:\n",
    "            I = get_gray_im(ET, Z, Z0)\n",
    "        else:\n",
    "            I = get_im(ET, Z, Z0)\n",
    "            \n",
    "        file_name = os.path.join(output_directory, hash_idx + 'small.jpg')\n",
    "        I.save(file_name)\n",
    "        if DISPLAY_IN_NOTEBOOK:\n",
    "            display(I)\n",
    "\n",
    "        domain_dict['n_rows'] = large_scale[0]\n",
    "        domain_dict['n_cols'] = large_scale[1]\n",
    "\n",
    "        ET, Z, Z0 = eq_iter.get_primitives(list_tuple, domain_dict)\n",
    "        if GRAYSCALE == True:\n",
    "            I = get_gray_im(ET, Z, Z0)\n",
    "        else:\n",
    "            I = get_im(ET, Z, Z0)\n",
    "            \n",
    "        file_name = os.path.join(output_directory, hash_idx + 'large.jpg')\n",
    "        I.save(file_name)\n",
    "        \n",
    "        print('%0.3f\\t 2 images time'%(time.time() - t0))\n",
    "        if DISPLAY_IN_NOTEBOOK:\n",
    "            display(I)\n",
    "\n",
    "tt = time.time() - cell_start_time\n",
    "print('\\n%i pairs written in %0.2f seconds'%(n_2_do, tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coloring logic\n",
    "    * HSV model - choose three result components\n",
    "        * Hue        (red to red) (0, 1) * 255          == visible spectrum colors\n",
    "        * Saturation (gray to solid color) (0, 1) * 255 == color intensity\n",
    "        * Value      (black to white) (0, 1) * 255      == brightness\n",
    "    * RGB conversion from HSV\n",
    "        * portable for multiple file formats\n",
    "        * norm for train - validate - test\n",
    "    * Escape-time algorithm produces\n",
    "        * Escape Time (integer matrix)\n",
    "        * Final Vector (Z - Z0)\n",
    "            * distance (float matrix)\n",
    "            * rotation (float matrix)\n",
    "****\n",
    "### Coloring component normalization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_component_color_range(Z0, Z, ET):\n",
    "    # Examine color ranges - for HSV - RGB conversion \n",
    "    Zd_t, Zr_t, ETn_t = ncp.etg_norm(Z0, Z, ET)\n",
    "    print('\\nZd_t', np.max(Zd_t), np.min(Zd_t))\n",
    "    print('Zr_t', np.max(Zr_t), np.min(Zr_t))\n",
    "    print('ETn_t', np.max(ETn_t), np.min(ETn_t))\n",
    "    \n",
    "view_component_color_range(Z0, Z, ET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## file nameing calls - time-stamp-name or hash-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_da = now_name(prefi_str=fcn_name, suffi_str='.jpg')\n",
    "print(do_da)\n",
    "d0_dat = hashy_list[0] + '.jpg'\n",
    "print(d0_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
