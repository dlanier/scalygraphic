{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Scaling with Machine Learning\n",
    "## Image production or Streaming\n",
    "\n",
    "### Inputs:\n",
    "    1) Number of image pairs\n",
    "    2) dictionary of {size_label_A: [pixels_high, pixels_wide], \n",
    "                      size_label_B: [pixels_high, pixels_wide]}\n",
    "    3) run directory\n",
    "    4) output directory\n",
    "    5) existing sets parameters.json (None for first run)\n",
    "****\n",
    "[PIL image](https://pillow.readthedocs.io/en/5.1.x/reference/Image.html#the-image-class) <br>\n",
    "****\n",
    "[GitHub scalygraphic](https://github.com/dlanier/scalygraphic/) <br>\n",
    "### Code adapted from FlyingMachineFractal (artistic history) \n",
    "[github.io/FlyingMachineFractal ](https://dlanier.github.io/FlyingMachineFractal/) <br>\n",
    "[FlyingMachineFractal on GitHub](https://github.com/dlanier/FlyingMachineFractal) <br>\n",
    "### Technique adapted from KnowEnG (BD2K) project\n",
    "[Parameterized directory structure management](https://github.com/KnowEnG/KnowEnG_Pipelines_Library/blob/master/knpackage/toolbox.py) <br>\n",
    "[yaml file example](https://github.com/KnowEnG/Samples_Clustering_Pipeline/blob/master/data/run_files/BENCHMARK_4_SC_cc_nmf_parallel_shared.yml) <br>\n",
    "[YAML depreciation !!!](https://github.com/yaml/pyyaml/wiki/PyYAML-yaml.load(input)-Deprecation) <br>\n",
    "****\n",
    "#### Rewrite HSV coloring\n",
    "[FMF graphic_utility.py](https://github.com/dlanier/FlyingMachineFractal/blob/master/src/graphic_utility.py) <br>\n",
    "[FMF numcolorpy.py](https://github.com/dlanier/FlyingMachineFractal/blob/master/src/numcolorpy.py) <br>\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better Idea *:->* generate parameters dictionary only - re-run at different scales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    ../src/im_scale_products.py\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import hashlib\n",
    "import inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "sys.path.insert(0, '../src/')\n",
    "\n",
    "import zplain as zp\n",
    "import eq_iter\n",
    "import deg_0_ddeq\n",
    "# import numcolorpy as ncp\n",
    "import impute_color as ncp\n",
    "\n",
    "def get_run_parameters(full_file_name, run_directory, results_directory):\n",
    "    \"\"\" Read input arguments from yaml file and localize run direcories\n",
    "    \n",
    "    Args:\n",
    "        full_file_name:     yaml file - parameters needed to run an option\n",
    "        run_directory:      directory where code may run & write temp files\n",
    "        images_directory:   output for image files\n",
    "\n",
    "    Returns:\n",
    "        run_parameters:     python dict eg. {   name_a: value_a, \n",
    "                                                name_b: value_b }\n",
    "    \"\"\"\n",
    "    with open(full_file_name, 'r') as fh:\n",
    "        run_parameters = yaml.safe_load(fh)\n",
    "\n",
    "    run_parameters[\"run_file\"] = full_file_name\n",
    "    run_parameters[\"run_directory\"] = run_directory\n",
    "    run_parameters[\"results_directory\"] = results_directory\n",
    "\n",
    "    return run_parameters\n",
    "\n",
    "\"\"\"     Constants (lookups):   ala import deg_0_ddeq\n",
    "\n",
    "        EQUS_DICT is an enumerated dictionary of the functions in module deg_0_ddeq\n",
    "        EQUS_DICT_NAMED_IDX is a dictionary - name: number index of EQUS_DICT \n",
    "\"\"\"\n",
    "EQUS_DICT = {k: v for k, v in enumerate(inspect.getmembers(deg_0_ddeq, inspect.isfunction))}\n",
    "EQUS_DICT_NAMED_IDX = {v[0]: k for k, v in EQUS_DICT.items()}\n",
    "\n",
    "def get_rand_eq_p_set():\n",
    "    \"\"\" get a random equation and parameter set from the deg_0_ddeq module\n",
    "    (No Args:)\n",
    "    Returns:\n",
    "        tuple:      (function_name, function_handle, parameter_set)\n",
    "    \"\"\"\n",
    "    n = np.random.randint(0,len(EQUS_DICT),1)\n",
    "    fcn_name, fcn = EQUS_DICT[n[0]]\n",
    "    p = fcn(0.0, None)\n",
    "\n",
    "    return (fcn_name, fcn, p)\n",
    "\n",
    "def get_eq_by_name(fcn_name):\n",
    "    \"\"\" Usage: function_handle = get_eq_by_name(fcn_name)\n",
    "    Args:\n",
    "        name of a function in deg_0_ddeq\n",
    "    \"\"\"\n",
    "    if fcn_name in EQUS_DICT_NAMED_IDX:\n",
    "        return EQUS_DICT[EQUS_DICT_NAMED_IDX[fcn_name]][1]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_random_domain(bounds_dict=None):\n",
    "    \"\"\" Usage: \n",
    "    domain_dict = get_random_domain(h, w, bounds_dict)\n",
    "    \n",
    "    Args:\n",
    "        bounds_dict:    min - max limits for keys eg.\n",
    "                            CP_magnitude_limits = {'min': 0, 'max': 7}\n",
    "                            ZM_limits           = {'min': np.finfo(float).eps, 'max': 2}\n",
    "                            theta_limits        = {'min': 0, 'max':2 * np.pi}\n",
    "                        \n",
    "    Returns:\n",
    "        domain_dict:    with keys:\n",
    "                            center_point\n",
    "                            zoom\n",
    "                            theta\n",
    "    \"\"\"\n",
    "    domain_dict = {}\n",
    "    if bounds_dict is None:\n",
    "        CP_magnitude_limits =   {'min': 0, 'max': 2}\n",
    "        ZM_limits =             {'min': np.finfo(float).eps, 'max': 1}\n",
    "        theta_limits =          {'min': 0, 'max':2 * np.pi}\n",
    "    else:\n",
    "        CP_magnitude_limits =   bounds_dict['CP_magnitude_limits']\n",
    "        ZM_limits =             bounds_dict['ZM_limits']\n",
    "        theta_limits =          bounds_dict['theta_limits']\n",
    "\n",
    "    r = np.random.uniform(low=0.0, high=2*np.pi) * 0.0+1.0j\n",
    "    m = np.random.uniform(low=CP_magnitude_limits['min'], high=CP_magnitude_limits['max'])\n",
    "    domain_dict['center_point'] = m*np.exp(r)\n",
    "    domain_dict['zoom'] = np.random.uniform(low=ZM_limits['min'], high=ZM_limits['max'])\n",
    "    domain_dict['theta'] = np.random.uniform(low=theta_limits['min'], high=theta_limits['max'])\n",
    "    \n",
    "    return domain_dict\n",
    "\n",
    "def sha256sum(s):\n",
    "    \"\"\" Usage:  hash_key = sha256sum(input_str)\n",
    "    \"\"\"\n",
    "    h  = hashlib.sha256()\n",
    "    h.update(bytes(s, 'ascii'))\n",
    "    \n",
    "    return h.hexdigest()\n",
    "\n",
    "def hash_parameters(domain_dict, fcn_name, p):\n",
    "    \"\"\" Usage: hash_key = hash_parameters(domain_dict, fcn_name, p)\n",
    "    \"\"\"\n",
    "    N_DEC = 15\n",
    "    f = zp.get_frame_from_dict(domain_dict)\n",
    "    s = zp.complex_frame_dict_to_string(f, N_DEC) + '\\n' + fcn_name\n",
    "    if isinstance(p, list):\n",
    "        p_str = ''\n",
    "        for p_n in p:\n",
    "            p_str += zp.complex_to_string(p_n, N_DEC)\n",
    "    else:\n",
    "        p_str = zp.complex_to_string(p, N_DEC)\n",
    "    \n",
    "    s += p_str\n",
    "    \n",
    "    return sha256sum(s)\n",
    "\n",
    "def get_im(ET, Z, Z0):\n",
    "    \"\"\" Usage: I = get_im(ET, Z, Z0)\n",
    "    \"\"\"\n",
    "    Zd, Zr, ETn = ncp.etg_norm(Z0, Z, ET)\n",
    "\n",
    "    A = np.zeros((domain_dict['n_rows'],domain_dict['n_cols'],3))\n",
    "    A[:,:,0] += ETn     # Hue\n",
    "    A[:,:,1] += Zr      # Saturation\n",
    "    A[:,:,2] += Zd      # Value\n",
    "    I = PIL.Image.fromarray(np.uint8(A * 255), 'HSV').convert('RGB')\n",
    "    \n",
    "    return I\n",
    "\n",
    "def get_gray_im(ET, Z, Z0, et_gray=False):\n",
    "    \"\"\" Usage: I = get_im(ET, Z, Z0)\n",
    "    \"\"\"\n",
    "    Zd, Zr, ETn = ncp.etg_norm(Z0, Z, ET)\n",
    "    \n",
    "    if et_gray:\n",
    "        I = PIL.Image.fromarray(np.uint8(ETn * 255), 'L')\n",
    "    else:\n",
    "        I = PIL.Image.fromarray(np.uint8(Zd * 255), 'L')\n",
    "    \n",
    "    return I\n",
    "\n",
    "def now_name(prefi_str=None, suffi_str=None):\n",
    "    \"\"\" get a human readable time stamp name \"\"\"\n",
    "    t0 = time.time()\n",
    "    t_dec = t0 - np.floor(t0)\n",
    "    ahora_nombre = time.strftime(\"%a_%d_%b_%Y_%H_%M_%S\", time.localtime()) \n",
    "    if prefi_str is None: prefi_str = ''\n",
    "    if suffi_str is None: suffi_str = ''\n",
    "        \n",
    "    return prefi_str + '_' + ahora_nombre + suffi_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example yaml file - generate a json file of non-dimensional image parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# create run_files dir if DNE\n",
    "run_file_directory = '../data/run_files/'\n",
    "if os.path.isdir(run_file_directory) == False:\n",
    "    os.makedirs(run_file_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile ../data/run_files/generate_json_nd_parameter_set.yml\n",
    "\n",
    "method: gen_nd_pars                 # Available methods: gen_im_set gen_nd_pars, stream_ims_frm_nd_pars\n",
    "    \n",
    "number_of_image_sets: 100\n",
    "results_directory:   ../results\n",
    "it_max:              64\n",
    "escape_dist_scale:         10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce very large set of unique figure run parameters\n",
    "[StackOverflow append json](https://stackoverflow.com/questions/12994442/how-to-append-data-to-a-json-file) <br>\n",
    "```python\n",
    "# Append JSON object to output file JSON array\n",
    "fname = \"somefile.txt\"\n",
    "if os.path.isfile(fname):\n",
    "    # File exists\n",
    "    with open(fname, 'a+') as outfile:\n",
    "        outfile.seek(-1, os.SEEK_END)\n",
    "        outfile.truncate()\n",
    "        outfile.write(',')\n",
    "        json.dump(data_dict, outfile)\n",
    "        outfile.write(']')\n",
    "else: \n",
    "    # Create file\n",
    "    with open(fname, 'w') as outfile:\n",
    "        array = []\n",
    "        array.append(data_dict)\n",
    "        json.dump(array, outfile)\n",
    "```\n",
    "### Else:\n",
    "[]() <br>\n",
    "```python\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create the connection\n",
    "cnx = sqlite3.connect(r'C:\\mydatabases\\bigdata.db')\n",
    "\n",
    "# create the dataframe from a query\n",
    "df = pd.read_sql_query(\"SELECT * FROM userdata\", cnx)\n",
    "```\n",
    "\n",
    "```bash\n",
    "TypeError: Object of type complex128 is not JSON serializable\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  method: gen_nd_pars\n",
      "                    number_of_image_sets: 1000\n",
      "                       results_directory: ../../ImagePars\n",
      "                                  it_max: 64\n",
      "                       escape_dist_scale: 10\n",
      "                                run_file: ../data/run_files/generate_json_nd_parameter_set.yml\n",
      "                           run_directory: ../../test_dir\n",
      "\n",
      "  1000 parameter sets in 0.19 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_non_dimensional_image_parameters_set(run_parameters):\n",
    "    \"\"\" generate a json file of unique parameter sets for generating images and multiple scales\n",
    "    ndip_dict, run_parameters = get_non_dimensional_image_parameters_set(run_parameters)\n",
    "    \"\"\"\n",
    "    ndim_dict = {}\n",
    "    \n",
    "    if not 'json_file_name' in run_parameters:\n",
    "        run_parameters['json_file_name'] = now_name('nd_par_set', '.json')\n",
    "        \n",
    "    number_of_image_sets = run_parameters['number_of_image_sets']\n",
    "    results_directory = run_parameters['results_directory']\n",
    "    it_max = run_parameters['it_max']\n",
    "    escape_dist_scale = run_parameters['escape_dist_scale']\n",
    "    json_file_name = run_parameters['json_file_name']\n",
    "    \n",
    "    for runrunrun in range(number_of_image_sets):\n",
    "        fcn_name, eq, p = get_rand_eq_p_set()\n",
    "        domain_dict = get_random_domain()\n",
    "        domain_dict['it_max'] = it_max\n",
    "        domain_dict['max_d'] = escape_dist_scale / domain_dict['zoom']\n",
    "        \n",
    "        hash_idx = hash_parameters(domain_dict, fcn_name, p)\n",
    "        ndim_dict[hash_idx] = {'domain_dict': domain_dict, 'fcn_name': fcn_name, 'p': p}\n",
    "\n",
    "    return ndim_dict, run_parameters\n",
    "\n",
    "\n",
    "run_file_name = '../data/run_files/generate_json_nd_parameter_set.yml'\n",
    "run_directory = '../../test_dir'\n",
    "results_directory = '../../ImagePars'\n",
    "run_parameters = get_run_parameters(run_file_name, run_directory, results_directory)\n",
    "\n",
    "run_parameters['number_of_image_sets'] = 1000\n",
    "for k, v in run_parameters.items():\n",
    "    print('%40s: %s'%(k, v))\n",
    "print()\n",
    "t_start = time.time()\n",
    "ndim_dict, run_parameters = get_non_dimensional_image_parameters_set(run_parameters)\n",
    "tt = time.time() - t_start\n",
    "print('%6i parameter sets in %0.2f seconds'%(run_parameters['number_of_image_sets'], tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\"\"\"\n",
    "domain_dict\n",
    "fcn_name\n",
    "p\n",
    "\"\"\"\n",
    "{'domain_dict': {'center_point': (0.9974570444592821+1.553447306052334j),\n",
    "  'zoom': 0.8564438540984382,\n",
    "  'theta': 3.3651668445664584,\n",
    "  'it_max': 64,\n",
    "  'max_d': 11.676188639974312},\n",
    " 'fcn_name': 'IslaLace',\n",
    " 'p': [0.444476893762, (0.508164683992+0.420921535772j)]}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                           Replace complex numbers for json limitation\n",
    "\"\"\"    {'scalygraphic_type': 'complex128', \n",
    "        'shape': [1,1], \n",
    "        'value': [r, c], \n",
    "        'n_dec': 12      }             \"\"\"\n",
    "def domain_dict_to_json_dict(domain_dict):\n",
    "    json_dict = {}\n",
    "    # recursively convert complex numbers to strings\n",
    "    return json_dict\n",
    "\n",
    "\n",
    "def json_dict_to_domain_dict(json_dict):\n",
    "    domain_dict = {}\n",
    "    return domain_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'domain_dict': {'center_point': (0.9974570444592821+1.553447306052334j),\n",
       "  'zoom': 0.8564438540984382,\n",
       "  'theta': 3.3651668445664584,\n",
       "  'it_max': 64,\n",
       "  'max_d': 11.676188639974312},\n",
       " 'fcn_name': 'IslaLace',\n",
       " 'p': [0.444476893762, (0.508164683992+0.420921535772j)]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keeze = list(ndim_dict.keys())\n",
    "ndim_dict[keeze[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'domain_dict': {'center_point': (0.345776779464405+0.5385154273441588j),\n",
       "  'zoom': 0.8264847476145545,\n",
       "  'theta': 5.98403439934556,\n",
       "  'it_max': 64,\n",
       "  'max_d': 12.099436836387541},\n",
       " 'fcn_name': 'IslaLace',\n",
       " 'p': [0.444476893762, (0.508164683992+0.420921535772j)]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndim_dict[keeze[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  method: gen_nd_pars\n",
      "                    number_of_image_sets: 1000000\n",
      "                       results_directory: ../../ImagePars\n",
      "                                  it_max: 64\n",
      "                       escape_dist_scale: 10\n",
      "                                run_file: ../data/run_files/generate_json_nd_parameter_set.yml\n",
      "                           run_directory: ../../test_dir\n",
      "                          json_file_name: nd_par_set_Fri_20_Sep_2019_13_47_59.json\n"
     ]
    }
   ],
   "source": [
    "for k, v in run_parameters.items():\n",
    "    print('%40s: %s'%(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                                               json no do dakine complex numbers \n",
    "\n",
    "test_dir = '../../images_json_test'\n",
    "if not os.path.isdir(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "json_file_name = os.path.join(test_dir, run_parameters['json_file_name'])\n",
    "json_file_name\n",
    "# with open(json_file_name, 'w') as fh:\n",
    "#     json.dump(ndip_dict, fh, indent=4, sort_keys=True)\n",
    "#                                                               json no do dakine complex numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'domain_dict': {'center_point': (0.21436349590304063+0.3338513644034249j),\n",
       "  'zoom': 0.7833952328522382,\n",
       "  'theta': 2.900318483886338,\n",
       "  'it_max': 64,\n",
       "  'max_d': 12.764948752102212},\n",
       " 'fcn_name': 'decPwrAFx',\n",
       " 'p': [1.7724538509055159, 1.13761386, -0.11556857]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keeze = list(ndip_dict.keys())\n",
    "ndip_dict[keeze[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                                   Type        Data/Info\n",
      "----------------------------------------------------------------\n",
      "EQUS_DICT                                  dict        n=9\n",
      "EQUS_DICT_NAMED_IDX                        dict        n=9\n",
      "PIL                                        module      <module 'PIL' from '/Libr<...>ackages/PIL/__init__.py'>\n",
      "autopep8                                   module      <module 'autopep8' from '<...>te-packages/autopep8.py'>\n",
      "deg_0_ddeq                                 module      <module 'deg_0_ddeq' from '../src/deg_0_ddeq.py'>\n",
      "eq_iter                                    module      <module 'eq_iter' from '../src/eq_iter.py'>\n",
      "get_eq_by_name                             function    <function get_eq_by_name at 0x11a07fd08>\n",
      "get_gray_im                                function    <function get_gray_im at 0x11ef5c158>\n",
      "get_im                                     function    <function get_im at 0x11a07ff28>\n",
      "get_non_dimensional_image_parameters_set   function    <function get_non_dimensi<...>eters_set at 0x11f0bad90>\n",
      "get_rand_eq_p_set                          function    <function get_rand_eq_p_set at 0x1134bfb70>\n",
      "get_random_domain                          function    <function get_random_domain at 0x11a07fd90>\n",
      "get_run_parameters                         function    <function get_run_parameters at 0x1133d3ae8>\n",
      "hash_parameters                            function    <function hash_parameters at 0x11a07fea0>\n",
      "hashlib                                    module      <module 'hashlib' from '/<...>ib/python3.7/hashlib.py'>\n",
      "inspect                                    module      <module 'inspect' from '/<...>ib/python3.7/inspect.py'>\n",
      "json                                       module      <module 'json' from '/Lib<...>hon3.7/json/__init__.py'>\n",
      "k                                          str         json_file_name\n",
      "ncp                                        module      <module 'numcolorpy' from '../src/numcolorpy.py'>\n",
      "ndip_dict                                  dict        n=1000000\n",
      "now_name                                   function    <function now_name at 0x11ef42e18>\n",
      "np                                         module      <module 'numpy' from '/Li<...>kages/numpy/__init__.py'>\n",
      "os                                         module      <module 'os' from '/Libra<...>3.7/lib/python3.7/os.py'>\n",
      "results_directory                          str         ../../ImagePars\n",
      "run_directory                              str         ../../test_dir\n",
      "run_file_name                              str         ../data/run_files/generat<...>json_nd_parameter_set.yml\n",
      "run_parameters                             dict        n=8\n",
      "sha256sum                                  function    <function sha256sum at 0x11a07fe18>\n",
      "sys                                        module      <module 'sys' (built-in)>\n",
      "t_start                                    float       1569005279.001306\n",
      "time                                       module      <module 'time' (built-in)>\n",
      "tt                                         float       155.37429308891296\n",
      "v                                          str         nd_par_set_Fri_20_Sep_2019_13_47_59.json\n",
      "warnings                                   module      <module 'warnings' from '<...>b/python3.7/warnings.py'>\n",
      "yaml                                       module      <module 'yaml' from '/Lib<...>ckages/yaml/__init__.py'>\n",
      "zp                                         module      <module 'zplain' from '../src/zplain.py'>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define for multiple iterations of next cell\n",
    "hashy_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1) RoyalZ\n",
      "3cf79c2b513229d8c311340a25f3976d3c72dceb4bc44c7d8f518a015bd26b85\n",
      "\n",
      "19.536\t 2 images time\n",
      "\n",
      "  2) ItchicuPpwrF\n",
      "a034c8d32c943cf5c760f63d89613f89f4ec74955ad37b416107079a7de28935\n",
      "\n",
      "18.285\t 2 images time\n",
      "\n",
      "  3) ElGato\n",
      "fcf622ce3dd73e7a731cfb2233678a6e3889991810e858298b6bc279881d2c5c\n",
      "\n",
      "14.145\t 2 images time\n",
      "\n",
      "  4) Nautuliz\n",
      "b29d551e0a4ca6af3269eec955367b735b2eab093bad01bf4f9ff69e3cbede8a\n",
      "\n",
      "3.651\t 2 images time\n",
      "\n",
      "  5) ElGato\n",
      "c3b5de1d5ba1bf88fd2f94a120e53bb56d2a22f822095647165b4d91da854ecb\n",
      "\n",
      "14.754\t 2 images time\n",
      "\n",
      "  6) starfish_ish_II\n",
      "e752eb438c61385c10fabed1a66e6589b3f3d0c1007c5a9edcdc473b0ff8f7c5\n",
      "\n",
      "19.098\t 2 images time\n",
      "\n",
      "  7) Nautuliz\n",
      "8f30f23076d983da225d53cffcb68807d10b65dc9760e4c7bdb920a134c3bf68\n",
      "\n",
      "2.615\t 2 images time\n",
      "\n",
      "  8) starfish_ish_II\n",
      "ed4937b7f41b04b37eb2bd26ef2777a2606ac2c9cd16c37eafd89c3bfcce614f\n",
      "\n",
      "20.294\t 2 images time\n",
      "\n",
      "  9) decPwrAFx\n",
      "1d7a49a7330fc871f117390b20f0511eb4290162bacf68a4b40aba18e38da1d1\n",
      "\n",
      "14.918\t 2 images time\n",
      "\n",
      " 10) IslaLace\n",
      "a078b48ea50a7a14fe11e05cf907563ff5d23d937098d6ef98534c5ed221e671\n",
      "\n",
      "5.377\t 2 images time\n",
      "\n",
      "10 pairs written in 132.68 seconds\n"
     ]
    }
   ],
   "source": [
    "cell_start_time = time.time()\n",
    "\n",
    "n_2_do = 10\n",
    "\n",
    "test_temporary_dir = '../../test_temporary_dir'\n",
    "if os.path.isdir(test_temporary_dir) == False:\n",
    "    os.makedirs(test_temporary_dir)\n",
    "\n",
    "DISPLAY_IN_NOTEBOOK = False\n",
    "\n",
    "small_scale = [128, 128]\n",
    "large_scale = [255, 255]\n",
    "output_directory = '../../ImagesFriday'\n",
    "if os.path.isdir(output_directory) == False:\n",
    "    os.makedirs(output_directory)\n",
    "    \n",
    "\n",
    "for k_do in range(n_2_do):\n",
    "    fcn_name, eq, p = get_rand_eq_p_set()\n",
    "    print('\\n%3i) %s'%(k_do+1, fcn_name))\n",
    "    domain_dict = get_random_domain()\n",
    "\n",
    "    domain_dict['it_max'] = 64\n",
    "    domain_dict['max_d'] = 10 / domain_dict['zoom']\n",
    "\n",
    "    hash_idx = hash_parameters(domain_dict, fcn_name, p)\n",
    "    if hash_idx in hashy_list:\n",
    "        print('\\n\\n\\t\\tImpossible! But! Skipping:\\n%s\\n'%(hash_idx))\n",
    "    else:\n",
    "        hashy_list.append(hash_idx)\n",
    "        print(hash_idx + '\\n')\n",
    "        domain_dict['n_rows'] = small_scale[0]\n",
    "        domain_dict['n_cols'] = small_scale[1]\n",
    "\n",
    "        domain_dict['dir_path'] = test_temporary_dir\n",
    "\n",
    "        list_tuple = [(eq, (p))]\n",
    "\n",
    "        t0 = time.time()\n",
    "        ET, Z, Z0 = eq_iter.get_primitives(list_tuple, domain_dict)\n",
    "        I = get_im(ET, Z, Z0)\n",
    "        file_name = os.path.join(output_directory, hash_idx + 'small.jpg')\n",
    "        I.save(file_name)\n",
    "        if DISPLAY_IN_NOTEBOOK:\n",
    "            display(I)\n",
    "\n",
    "        domain_dict['n_rows'] = large_scale[0]\n",
    "        domain_dict['n_cols'] = large_scale[1]\n",
    "\n",
    "        ET, Z, Z0 = eq_iter.get_primitives(list_tuple, domain_dict)\n",
    "        I = get_im(ET, Z, Z0)\n",
    "        file_name = os.path.join(output_directory, hash_idx + 'large.jpg')\n",
    "        I.save(file_name)\n",
    "        \n",
    "        print('%0.3f\\t 2 images time'%(time.time() - t0))\n",
    "        if DISPLAY_IN_NOTEBOOK:\n",
    "            display(I)\n",
    "\n",
    "tt = time.time() - cell_start_time\n",
    "print('\\n%i pairs written in %0.2f seconds'%(n_2_do, tt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## file nameing ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IslaLace_Fri_20_Sep_2019_07_56_43.jpg\n",
      "3cf79c2b513229d8c311340a25f3976d3c72dceb4bc44c7d8f518a015bd26b85.jpg\n"
     ]
    }
   ],
   "source": [
    "do_da = now_name(prefi_str=fcn_name, suffi_str='.jpg')\n",
    "print(do_da)\n",
    "d0_dat = hashy_list[0] + '.jpg'\n",
    "print(d0_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coloring logic\n",
    "    * HSV model - choose three result components\n",
    "        * Hue        (red to red) (0, 1) * 255          == visible spectrum colors\n",
    "        * Saturation (gray to solid color) (0, 1) * 255 == color intensity\n",
    "        * Value      (black to white) (0, 1) * 255      == brightness\n",
    "    * RGB conversion from HSV\n",
    "        * portable for multiple file formats\n",
    "        * norm for train - validate - test\n",
    "    * Escape-time algorithm produces\n",
    "        * Escape Time (integer matrix)\n",
    "        * Final Vector (Z - Z0)\n",
    "            * distance (float matrix)\n",
    "            * rotation (float matrix)\n",
    "****\n",
    "### Coloring component normalization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_component_color_range(Z0, Z, ET):\n",
    "    # Examine color ranges - for HSV - RGB conversion \n",
    "    Zd_t, Zr_t, ETn_t = ncp.etg_norm(Z0, Z, ET)\n",
    "    print('\\nZd_t', np.max(Zd_t), np.min(Zd_t))\n",
    "    print('Zr_t', np.max(Zr_t), np.min(Zr_t))\n",
    "    print('ETn_t', np.max(ETn_t), np.min(ETn_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
